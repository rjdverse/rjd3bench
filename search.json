[{"path":"https://rjdverse.github.io/rjd3bench/articles/rjd3bench.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Temporal disaggregation and Benchmarking methods based on JDemetra+ v3.x","text":"methods implemented package rjd3bench intend bridge gap lack high frequency time series temporal /contemporaneous inconsistencies high frequency series corresponding low frequency series. Although can issue fields research dealing time series, methods temporal disaggregation, interpolation, benchmarking, reconciliation calendarization often encountered production official statistics. example, National Accounts often compiled according two frequencies production: annual series, low frequency data, based precise detailed sources quarterly series, high frequency data, usually rely less accurate sources give information timelier basis. case, use temporal disaggregation, benchmarking, reconciliation methods can used achieve consistency annual quarterly national accounts time. package rjd3bench R interface highly efficient algorithms modeling developed official ‘JDemetra+ 3.x’ software. provides wide variety methods, included suggested ESS guidelines temporal disaggregation, benchmarking reconciliation (Eurostat, 2018).","code":""},{"path":"https://rjdverse.github.io/rjd3bench/articles/rjd3bench.html","id":"set-up-data","dir":"Articles","previous_headings":"","what":"Set-up & Data","title":"Temporal disaggregation and Benchmarking methods based on JDemetra+ v3.x","text":"illustrate various methods using two datasets: Retail dataset contains monthly figures retail activity various categories goods services 1992 2010. qna_data list two datasets. first data set ‘B1G_Y_data’ includes three annual benchmark series Belgian annual value added period 2009-2020 chemical industry (CE), construction (FF) transport services (HH). second data set ‘TURN_Q_data’ includes corresponding quarterly indicators (modified) production indicators derived VAT statistics covering period 2009Q1-2021Q4.","code":"library(\"rjd3bench\") Retail <- rjd3toolkit::Retail qna_data <- rjd3bench::qna_data"},{"path":"https://rjdverse.github.io/rjd3bench/articles/rjd3bench.html","id":"temporal-disaggregation-and-interpolation-methods","dir":"Articles","previous_headings":"","what":"Temporal disaggregation and interpolation methods","title":"Temporal disaggregation and Benchmarking methods based on JDemetra+ v3.x","text":"Temporal disaggregation interpolation related (benchmarking). share similar properties methods differ purpose. Temporal disaggregation usually associated flow series. purpose break low frequency time series higher frequency time series, low frequency series correspond sum average corresponding higher frequency series. Interpolation usually arises context stock series. purpose estimate missing values time points known data points given low frequency series. example, annual series can typically corresponds fourth quarter twelfth month quarterly monthly series purpose obtain estimates quarters months. Chow-Lin method variants, separate function considered temporal disaggregation interpolation. case methods two integrated single function. Furthermore, raw version available functions temporal_disaggregation() temporal_interpolation() related Chow-Lin method variants. functions temporal_disaggregation_raw() temporal_interpolation_raw() enable user deal atypical frequency data frequency ratio. Note benchmarking, function denton_raw() also available.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/articles/rjd3bench.html","id":"chow-lin-fernandez-and-litterman","dir":"Articles","previous_headings":"Temporal disaggregation and interpolation methods","what":"Chow-Lin, Fernandez and Litterman","title":"Temporal disaggregation and Benchmarking methods based on JDemetra+ v3.x","text":"Eurostat (2018) recommends use regression-based models purpose temporal disaggregation. Among , retrieve Chow-Lin method variants Fernandez Litterman. Let YTY_T, T=1,...,mT=1,...,m, xtx_t, t=1,...,nt=1,...,n, , respectively observed low frequency benchmark high-frequency indicator unknown high frequency variable yty_t. Chow-Lin, Fernandez Litterman can expressed equation, different models error term: yt=xtβ+ut y_t = x_t\\beta+u_t  ut=ϕut−1+ϵtu_t = \\phi u_{t-1} + \\epsilon_t, |ϕ|<1|\\phi| < 1 (Chow-Lin), ut=ut−1+ϵtu_t = u_{t-1} + \\epsilon_t (Fernandez), ut=ut−1+ϕ(Δut−1)+ϵtu_t = u_{t-1} + \\phi(\\Delta u_{t-1}) + \\epsilon_t, |ϕ|<1|\\phi| < 1 (Litterman) temporal constraint : Y=Cy, Y = Cy,  C=Im⊗cC = I_m \\otimes c, cc row vector size ss frequency ratio disaggregated/interpolated series low frequency benchmark. distinction temporal disaggregation interpolation lies definition vector c: Temporal disaggregation: c=[1,1,...,1]c = [1,1,...,1] aggregation (e.g., flow variables) c=[1/s,1/s,...,1/s]c = [1/s,1/s,...,1/s] average conversion (e.g., indexes) Interpolation: c=[0,0,...,1]c = [0,0,...,1] low frequency series corresponds last value interpolated series, c=[1,0,...,0]c = [1,0,...,0] ’s first value, etc. (e.g., stock variables) xtx_t observed high frequency, yty_t observed low frequency, therefore number effective observations estimate parameters number observations low-frequency benchmark. regression-based Chow-Lin method variants Fernandez Litterman can called functions temporal_disaggregation() temporal_interpolation(). two functions require ts object input series deal usual frequency conversion (.e. annual quarterly, annual monthly quarterly monthly). Alternatively, functions temporal_disaggregation_raw() temporal_interpolation_raw() require numeric vector input series extend previous functions way can deal atypical frequency series frequency ratio. output functions temporal_disaggregation(), temporal_interpolation(), temporal_disaggregation_raw() temporal_interpolation_raw() contains important information regression including estimates model coefficients covariance matrix, decomposition disaggregated/interpolated series information residuals. print() summary() functions can applied output object. plot() function, displays decomposition disaggregated/interpolated series regression smoothing effect, can applied output object functions temporal_disaggregation() temporal_interpolation().","code":"# Example 1: TD using Chow-Lin to disaggregate annual value added in construction sector using a quarterly indicator Y <- ts(qna_data$B1G_Y_data[, \"B1G_FF\"], frequency = 1, start = c(2009, 1)) x <- ts(qna_data$TURN_Q_data[, \"TURN_INDEX_FF\"], frequency = 4, start = c(2009, 1)) td <- rjd3bench::temporal_disaggregation(Y, indicators = x)  y <- td$estimation$disagg # the disaggregated series print(td) summary(td) plot(td)  # Example 2: interpolation using Fernandez without indicator when the last value (default) of the interpolated series is the one consistent with the low frequency series. Y <- rjd3toolkit::aggregate(rjd3toolkit::Retail$RetailSalesTotal, 1) ti <- temporal_interpolation(Y, indicators = NULL, model = \"Rw\", freq = 4, nfcsts = 2) y <- ti$estimation$interp # the interpolated series  # Example 3: TD of atypical frequency data using Fernandez with an offset of 1 period Y <- c(500,510,525,520) x <- c(97,        98, 98.5, 99.5, 104, 99,        100, 100.5, 101, 105.5, 103,        104.5, 103.5, 104.5, 109, 104,        107, 103, 108, 113, 110) td_raw <- temporal_disaggregation_raw(Y, indicators = x, startoffset = 1,  model = \"Rw\", freqratio = 5) y <- td_raw$estimation$disagg # the disaggregated series  # Example 4: interpolation of atypical frequency data using Fernandez without offset, when the first value of the interpolated  series is the one consistent with the low frequency series. Y <- c(500,510,525,520) x <- c(490, 492.5, 497.5, 520, 495,        500, 502.5, 505, 527.5, 515,        522.5, 517.5, 522.5, 545, 520,        535, 515, 540, 565, 550,        560) ti_raw <- temporal_interpolation_raw(Y, indicators = x,  model = \"Rw\", freqratio = 5, obsposition = 1) y <- ti_raw$estimation$interp"},{"path":"https://rjdverse.github.io/rjd3bench/articles/rjd3bench.html","id":"model-based-denton","dir":"Articles","previous_headings":"Temporal disaggregation and interpolation methods","what":"Model-based Denton","title":"Temporal disaggregation and Benchmarking methods based on JDemetra+ v3.x","text":"Denton method variants usually expressed mathematical terms constrained minimization problem. example, widely used Denton proportional first difference (PFD) method usually expressed follows: minyt∑t=2n[ytxt−yt−1xt−1]2 min_{y_t}\\sum^n_{t=2}\\biggl[\\frac{y_t}{x_t}-\\frac{y_{t-1}}{x_{t-1}}\\biggr]^2  subject temporal constraint (flow variables) ∑tyt=YT \\sum_{t} y_t = Y_T  yty_t value estimate high frequency series period t, xtx_t value high frequency indicator period t YTY_T value low frequency series (.e. benchmark series) period T. Equivalently, Denton PFD method can also expressed statistical model considering following state space representation $$ \\begin{aligned} y_t &= \\beta_t x_t \\\\ \\beta_{t+1} &= \\beta_t + \\varepsilon_t \\qquad \\varepsilon_t \\sim {\\sf NID}(0, \\sigma^2_{\\varepsilon}) \\end{aligned} $$ temporal constraints taken care considering cumulated series ytcy^c_t instead original series yty_t. Hence, last high frequency period (example, last quarter year) observed corresponds value benchmark. value periods initially defined missing estimated maximum likelihood. alternative representation Denton PFD method interesting allows flexibility. might now include outliers - namely, level shift(s) Benchmark Indicator ratio - otherwise induce undesirable wave effects. Outliers intensity defined changing value innovation variances. also possibility freeze disaggregated series specific period(s) prior certain date fixing high-frequency BI ratio(s). Following principle movement preservation inherent Denton, model-based Denton PFD method constitutes interesting alternative temporal disaggregation, interpolation benchmarking. link presentation subject include comparison regression-based methods temporal disaggregation. model-base Denton method can applied denton_modelbased() function. output denton_modelbased() function contains information disaggregated/interpolated series BI ratio well respecting errors making possible construct confidence intervals. print(), summary() plot() functions can also applied output object.plot() function displays disaggregated series BI ratio together respective 95% confidence interval.","code":"# Example: Use of model-based Denton for temporal disaggregation Y <- ts(qna_data$B1G_Y_data[, \"B1G_FF\"], frequency = 1, start = c(2009, 1)) x <- ts(qna_data$TURN_Q_data[, \"TURN_INDEX_FF\"], frequency = 4, start = c(2009, 1)) td_mbd <- rjd3bench::denton_modelbased(Y, x, outliers = list(\"2020-01-01\" = 100, \"2020-04-01\" = 100))  y_mbd <- td_mbd$estimation$disagg plot(td_mbd)"},{"path":"https://rjdverse.github.io/rjd3bench/articles/rjd3bench.html","id":"autoregressive-distributed-lag-adl-models","dir":"Articles","previous_headings":"Temporal disaggregation and interpolation methods","what":"Autoregressive Distributed Lag (ADL) Models","title":"Temporal disaggregation and Benchmarking methods based on JDemetra+ v3.x","text":"(Upcoming content)","code":""},{"path":"https://rjdverse.github.io/rjd3bench/articles/rjd3bench.html","id":"benchmarking-methods","dir":"Articles","previous_headings":"","what":"Benchmarking methods","title":"Temporal disaggregation and Benchmarking methods based on JDemetra+ v3.x","text":"benchmarking problem arises time series data target variable measured two different frequencies different levels accuracy. Typically, high frequency series less reliable low frequency series, referred benchmark. Thus, benchmarking process adjusting high frequency series make consistent reliable low frequency series. temporal disaggregation/interpolation method Chow-Lin variants, raw version denton() benchamrking method made available user. function denton_raw() enables user deal atypical frequency data frequency ratio.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/articles/rjd3bench.html","id":"denton","dir":"Articles","previous_headings":"Benchmarking methods","what":"Denton","title":"Temporal disaggregation and Benchmarking methods based on JDemetra+ v3.x","text":"Denton methods relies principle movement preservation. exist several variants corresponding different definitions movement preservation: additive first difference (AFD), proportional first difference (PFD), additive second difference (ASD), proportional second difference (PSD). widely used Denton PFD variant. Let YTY_T, T=1,...,mT=1,...,m, xtx_t, t=1,...,nt=1,...,n, , respectively temporal benchmarks high-frequency preliminary values unknown target variable yty_t. objective function Denton PFD method follows (considering small modification suggested Cholette deal starting conditions problem): minyt∑t=2n[ytxt−yt−1xt−1]2 min_{y_t}\\sum^n_{t=2}\\biggl[\\frac{y_t}{x_t}-\\frac{y_{t-1}}{x_{t-1}}\\biggr]^2  objective function minimized subject temporal aggregation constraints ∑tϵTyt=YT\\sum_{t\\epsilon T} y_t = Y_T, T=1,...,mT=1,...,m (flows variables). words, benchmarked series estimated way “Benchmark--Indicator” ratio ytxt\\frac{y_t}{x_t} remains smooth possible, often key interest benchmarking. literature (see example Di Fonzo Marini, 2011), Denton PFD generally considered good approximation GRP method, meaning preserves period--period growth rates preliminary series. also argued many applications, Denton PFD appropriate GRP method deals linear problem computationally easier, suffer issues related time irreversibility singular objective function yty_t approaches 0 (see Daalmans et al, 2018). Denton methods can called denton() function can deal usual frequency conversion (.e. annual quarterly, annual monthly quarterly monthly). Alternatively, denton_raw() function requires numeric vector input series, extends denton() function way can deal atypical frequency series frequency ratio. denton() denton_raw() functions return high frequency series benchmarked Denton method.","code":"# Example 1: use of Denton method for benchmarking Y <- ts(qna_data$B1G_Y_data[, \"B1G_HH\"], frequency = 1, start = c(2009, 1))  y_den0 <- rjd3bench::denton(t = Y, nfreq = 4) # denton PFD without high frequency series  x <- y_den0 + rnorm(n = length(y_den0), mean = 0, sd = 10) y_den1 <- rjd3bench::denton(s = x, t = Y) # denton PFD (= the default) y_den2 <- rjd3bench::denton(s = x, t = Y, d = 2, mul = FALSE) # denton ASD  # Example 2: use of of Denton method for benchmarking atypical frequency data Y <- c(500,510,525,520) x <- c(97, 98, 98.5, 99.5, 104,        99, 100, 100.5, 101, 105.5,        103, 104.5, 103.5, 104.5, 109,        104, 107, 103, 108, 113,        110)  y_denraw <- denton_raw(x, Y, freqratio = 5) # for example, x and Y could be annual and quiquennal series respectively"},{"path":"https://rjdverse.github.io/rjd3bench/articles/rjd3bench.html","id":"grp","dir":"Articles","previous_headings":"Benchmarking methods","what":"Growth rate preservation (GRP)","title":"Temporal disaggregation and Benchmarking methods based on JDemetra+ v3.x","text":"GRP explicitly preserves period--period growth rates preliminary series. Let YTY_T, T=1,...,mT=1,...,m, xtx_t, t=1,...,nt=1,...,n, , respectively temporal benchmarks high-frequency preliminary values unknown target variable yty_t. Cauley Trager(1981) consider following objective function: f(x)=∑t=2n(ytyt−1−xtxt−1)2 f(x) = \\sum_{t=2}^{n}\\left(\\frac{y_t}{y_{t-1}} - \\frac{x_t}{x_{t-1}}\\right)^2  look values yt*y_t^*, t=1,...,nt=1,...,n, minimize subject temporal aggregation constraints ∑tϵTyt=YT\\sum_{t\\epsilon T} y_t = Y_T, T=1,...,mT=1,...,m (flows variables). words, benchmarked series estimated way temporal dynamics; expressed growth rates yt*yt−1*\\frac{y_t^*}{y_{t-1}^*}, t=2,...,nt=2,...,n, “close possible” temporal dynamics preliminary series, “distance” preliminary growth rates xtxt−1\\frac{x_t}{x_{t-1}} given sum squared differences. (Di Fonzo, Marini, 2011) objective function considered Cauley Trager natural measure movement time series one expect, usually slightly better Denton PFD method preserving movement series (Di Fonzo, Marini, 2011). However, unlike Denton PFD method deals linear problem, GRP solves difficult nonlinear problem. Furthermore, GRP method suffers couple drawbacks, time irreversibility potential singularities objective function yt−1y_{t-1} approaches 0, lead undesirable results (see Daalmans et al, 2018). standard objective function GRP considered Cauley Trager defined means apply benchmarking forward. Alternatively, apply backward, means performing benchmarking reversed time series. previsouly mentionned, equivalent using GRP method. altenatives, Daalmans et al (2018) proposed two objective functions GRP (symmetric GRP logarithmic GRP) “time symmetric”. Backward GRP: f(x)=∑t=2n(yt−1yt−xt−1xt)2 f(x) = \\sum_{t=2}^{n}\\left(\\frac{y_{t-1}}{y_t} - \\frac{x_{t-1}}{x_t}\\right)^2  Symmetric GRP: f(x)=12∑t=2n(ytyt−1−xtxt−1)2+12∑t=2n(yt−1yt−xt−1xt)2 f(x) = \\frac{1}{2} \\sum_{t=2}^{n}\\left(\\frac{y_t}{y_{t-1}} - \\frac{x_t}{x_{t-1}}\\right)^2 +  \\frac{1}{2} \\sum_{t=2}^{n}\\left(\\frac{y_{t-1}}{y_t} - \\frac{x_{t-1}}{x_t}\\right)^2  Logarithmic GRP: f(x)=∑t=2n(log(ytyt−1)−log(xtxt−1))2 f(x) = \\sum_{t=2}^{n}\\left(log\\left(\\frac{y_t}{y_{t-1}}\\right) - log\\left(\\frac{x_t}{x_{t-1}}\\right) \\right)^2 GRP method, corresponding method Cauley Trager, using solution proposed Di Fonzo Marini (2011), can called grp() function. alternative objective function suggested Daalmans et al (2018) can also considered. grp() function returns high frequency series benchmarked GRP method.","code":"# Example: use GRP method for benchmarking Y <- ts(qna_data$B1G_Y_data[, \"B1G_HH\"], frequency = 1, start = c(2009, 1)) y_den0 <- rjd3bench::denton(t = Y, nfreq = 4) x <- y_den0 + rnorm(n = length(y_den0), mean = 0, sd = 10)  y_grpf <- rjd3bench::grp(s = x, t = Y) y_grpl <- rjd3bench::grp(s = x, t = Y, objective = \"Log\")"},{"path":"https://rjdverse.github.io/rjd3bench/articles/rjd3bench.html","id":"cubic-splines","dir":"Articles","previous_headings":"Benchmarking methods","what":"Cubic splines","title":"Temporal disaggregation and Benchmarking methods based on JDemetra+ v3.x","text":"Cubic splines piecewise cubic functions linked together way guarantee smoothness data points. Additivity constraints added benchmarking purpose sub-period estimates derived spline. sub-period indicator (disaggregated series) used, cubic splines longer drawn based low frequency data Benchmark--Indicator (BI ratio) one smoothed. Sub-period estimates simply product smoothed high frequency BI ratio indicator. method can called cubicspline() function. examples use : cubicspline() function returns high frequency series benchmarked cubic spline method.","code":"y_cs1 <- rjd3bench::cubicspline(t = Y, nfreq = 4) # example of cubic spline without high frequency series (smoothing)  x <- y_cs1 + rnorm(n = length(y_cs1), mean = 0, sd = 10) y_cs2 <- rjd3bench::cubicspline(s = x, t = Y) # example of cubic spline with a high frequency series to benchmark"},{"path":"https://rjdverse.github.io/rjd3bench/articles/rjd3bench.html","id":"cholette","dir":"Articles","previous_headings":"Benchmarking methods","what":"Cholette method","title":"Temporal disaggregation and Benchmarking methods based on JDemetra+ v3.x","text":"Cholette method based benchmarking methodology developed Statistics Canada. generalized method relying principle movement preservation encompasses benchmarking methods. Denton method (AFD PFD variants), well naive pro-rating method, emerge particular cases Cholette method. Let YTY_T, T=1,...,mT=1,...,m, xtx_t, t=1,...,nt=1,...,n, , respectively temporal benchmarks high-frequency preliminary values unknown target variable yty_t. objective function Cholette method follows (Quenneville et al, 2006): f(x)=(1−ρ2)(x1−y1|x1|λ)2+∑t=2n[(xt−yt|xt|λ)−ρ(xt−1−yt−1|xt−1|λ)]2 f(x) = (1-\\rho^2) \\left(\\frac{x_1 - y_1}{|x_1|^\\lambda}\\right)^2 + \\sum_{t=2}^{n}\\left[\\left(\\frac{x_t - y_t}{|x_t|^\\lambda}\\right) - \\rho \\left(\\frac{x_{t-1} - y_{t-1}}{|x_{t-1}|^\\lambda}\\right)\\right]^2  objective function minimized subject temporal aggregation constraints ∑tϵTyt=YT\\sum_{t\\epsilon T} y_t = Y_T, T=1,...,mT=1,...,m (flows variables). method driven couple parameters: adjustment model parameter λ\\lambda, λ∈ℝ\\lambda \\\\mathbb{R}. Set λ=1\\lambda = 1 proportional benchmarking model. Two choices λ=0\\lambda = 0 additive benchmarking model; λ=0.5\\lambda = 0.5 ρ=0\\rho = 0, naive pro-rating method. smoothing parameter ρ\\rho, 0≤ρ≤10 \\leq \\rho \\leq 1. ρ\\rho determines degree movement preservation. λ=1\\lambda = 1, closer ρ\\rho 1, smoother ratios benchmarks corresponding totals preliminary series better movement latter preserved. Cholette method also provides possibility considering bias correction factor, expected discrepancy benchmarks high-frequency preliminary series. additive multiplicative bias correction factor estimated respectively : ba=∑T=1mYT−∑T=1m∑tϵTxtmbm=∑T=1mYT∑T=1m∑tϵTxt \\begin{aligned} b_a &= \\frac{\\sum_{T=1}^{m}{Y_T} - \\sum_{T=1}^{m}{\\sum_{t\\epsilon T}x_t}}{m} \\\\ b_m &= \\frac{\\sum_{T=1}^{m}{Y_T}}{\\sum_{T=1}^{m}{\\sum_{t\\epsilon T}x_t}} \\end{aligned}  bias correction factor considered, preliminary series re-scaled objective function : xt*x_t^* replaces xtx_t, xt*=ba+xtx_t^*=b_a+x_t additive case xt*=bm×xtx_t^*=b_m \\times x_t multiplicative case. rationale considering bias correction factor method provided Dagum Cholette (2006, Ch. 6). mainly impacts observations end series covered benchmark. particular, ρ<1\\rho < 1, Benchmark--Indicator ratios (BI ratios) end series converge bias correction factor. default, bias considered, meaning expected systematic bias benchmarks preliminary series (ba=0b_a = 0 bm=1b_m = 1). Cholette method widely used benchmark seasonally adjusted series annual totals derived raw series. purpose, Quenneville et al (2006) argues undesirable feature Denton PFD method repeats last BI ratio observations end series covered benchmark. observations without benchmark, best estimate BI-ratio estimated value bias; , repeating last value appropriate. Instead, obtain smooth transition last BI-ratio bias, one can set ρ<1\\rho < 1. observations benchmark, BI-ratios closer obtained Denton PFD method (ρ=1\\rho = 1) smoother ρ→1\\rho \\1. pragmatic benchmarking method routinely applicable large numbers seasonal time series Dagum Cholette (2006) recommend proportional benchmarking method (λ=1\\lambda = 1) value ρ=0.90\\rho = 0.90 monthly series ρ=0.903=0.729\\rho = 0.90^3= 0.729 quarterly series. alternative estimate autocorrelation structure error instead using default values. Cholette method can called cholette() function. cholette() function returns high frequency series benchmarked Cholette method. noted , practice, benchmarked series estimated based equivalent state space representation Cholette method described , makes possible obtain estimates efficient way.","code":"# Example: use Cholette method for benchmarking Y <- ts(qna_data$B1G_Y_data[, \"B1G_HH\"], frequency = 1, start = c(2009, 1)) xn <- c(rjd3bench::denton(t = Y, nfreq = 4) + rnorm(n = length(Y)*4, mean = 0, sd = 10), 5750, 5800) x <- ts(xn, start = start(Y), frequency = 4)  rjd3bench::cholette(s = x, t = Y, rho = 0.729, lambda = 1, bias = \"Multiplicative\")  # proportional benchmarking rjd3bench::cholette(s = x, t = Y, rho = 0.729, lambda = 1) # proportional benchmarking with no bias (assuming bm=1) rjd3bench::cholette(s = x, t = Y, rho = 0.729, lambda = 0, bias = \"Additive\")  # additive benchmarking  rjd3bench::cholette(s = x, t = Y, rho = 1, lambda = 1) # Denton PFD rjd3bench::cholette(s = x, t = Y, rho = 0, lambda = 0.5) # pro-rating"},{"path":[]},{"path":"https://rjdverse.github.io/rjd3bench/articles/rjd3bench.html","id":"multivariate-cholette","dir":"Articles","previous_headings":"Reconciliation and multivariate temporal disaggregation","what":"Multivariate Cholette","title":"Temporal disaggregation and Benchmarking methods based on JDemetra+ v3.x","text":"multivariate extension Cholette benchmarking method can used purpose reconciliation. standard benchmarking methods consider one target series time, reconciliation techniques aim restore consistency system time series regards contemporaneous temporal constraints. Reconciliation techniques typically needed total components estimated independently (-called direct approach). multivariate Cholette method relies principle movement preservation encompasses reconciliation methods multivariate Denton method. Let Yi,TY_{,T}, T=1,...,mT=1,...,m, =1,...,Ii=1,...,, set temporal benchmarks zk,tz_{k,t}, t=1,...,nt=1,...,n, k=1,...,Kk=1,...,K, set contemporaneous constraints xi,tx_{,t} high-frequency preliminary values set unknown target variables yi,ty_{,t}. objective function multivariate Cholette method : f(x)=(1−ρ2)∑=1I(xi,1−yi,1|xi,1|λ)2+∑=1I∑t=2n[(xi,t−yi,t|xi,t|λ)−ρ(xi,t−1−yi,t−1|xi,t−1|λ)]2 f(x) = (1-\\rho^2) \\sum_{=1}^{}\\left(\\frac{x_{,1} - y_{,1}}{|x_{,1}|^\\lambda}\\right)^2 + \\sum_{=1}^{}\\sum_{t=2}^{n}\\left[\\left(\\frac{x_{,t} - y_{,t}}{|x_{,t}|^\\lambda}\\right) - \\rho \\left(\\frac{x_{,t-1} - y_{,t-1}}{|x_{,t-1}|^\\lambda}\\right)\\right]^2  objective function minimized subject temporal aggregation constraints ∑tϵTyi,t=Yi,T\\sum_{t\\epsilon T} y_{,t} = Y_{,T}, contemporaneous constraints given ∑jϵJkωk,jxj,t=zk,t\\sum_{j\\epsilon J_k}\\omega_{k,j}x_{j,t} = z_{k,t}. method may also considered absence temporal aggregation constraints. contemporaneous constraints imposed altering dynamic movements series little possible. hand, absence contemporaneous constraint less relevant, just equivalent applying univariate Cholette method preliminary series separately. univariate case, multivariate Cholette method driven couple parameters: adjustment model parameter λ\\lambda, λ∈ℝ\\lambda \\\\mathbb{R}. Set λ=0\\lambda = 0 additive benchmarking model λ\\lambda close 1 approach proportional benchmarking model. Unlike univariate case, considering pure proportional model setting λ=1\\lambda = 1 recommended. Indeed, due addition contemporaneous constraints, fact ratio benchmarked series preliminary series preserved (level preliminary series) may result benchmarked series whose level different preliminary series. Finally, naive pro-rating method corresponds setting λ=0.5\\lambda = 0.5 ρ=0\\rho = 0. smoothing parameter ρ\\rho, 0≤ρ≤10 \\leq \\rho \\leq 1. ρ\\rho determines degree movement preservation. λ=1\\lambda = 1, closer ρ\\rho 1, smoother ratios benchmarks corresponding totals preliminary series better movement latter preserved. multivariate Cholette method can called multivariatecholette() function. multivariatecholette() function returns list benchmarked series, fulfilling contemporary temporal constraints (). noted , practice, benchmarked series estimated based equivalent state space representation multivariate Cholette method described , makes possible obtain estimates efficient way.","code":"# Example: use the multivariate Cholette method for reconciliation x1 <- ts(c(7, 7.2, 8.1, 7.5, 8.5, 7.8, 8.1, 8.4), frequency = 4, start = c(2010, 1)) x2 <- ts(c(18, 19.5, 19.0, 19.7, 18.5, 19.0, 20.3, 20.0), frequency = 4, start = c(2010, 1)) x3 <- ts(c(1.5, 1.8, 2, 2.5, 2.0, 1.5, 1.7, 2.0), frequency = 4, start = c(2010, 1))  z <- ts(c(27.1, 29.8, 29.9, 31.2, 29.3, 27.9, 30.9, 31.8), frequency = 4, start = c(2010, 1))  Y1 <- ts(c(30.0, 30.6), frequency = 1, start = c(2010, 1)) Y2 <- ts(c(80.0, 81.2), frequency = 1, start = c(2010, 1)) Y3 <- ts(c(8.0, 8.1), frequency = 1, start = c(2010, 1))  ### check consistency between temporal and contemporaneous constraints lfs <- cbind(Y1,Y2,Y3) rowSums(lfs) - stats::aggregate.ts(z) # should all be 0  data_list <- list(x1 = x1, x2 = x2, x3 = x3, z = z, Y1 = Y1, Y2 = Y2, Y3 = Y3) tc <- c(\"Y1 = sum(x1)\", \"Y2 = sum(x2)\", \"Y3 = sum(x3)\") # temporal constraints cc <- c(\"z = x1+x2+x3\") # contemporaneous constraints  multivariatecholette(xlist = data_list, tcvector = tc, ccvector = cc, rho = 1, lambda = .5) # Denton multivariatecholette(xlist = data_list, tcvector = tc, ccvector = cc, rho = 0.729, lambda = .5) # Cholette multivariatecholette(xlist = data_list, tcvector = NULL, ccvector = cc, rho = 1, lambda = .5) # no temporal constraints"},{"path":"https://rjdverse.github.io/rjd3bench/articles/rjd3bench.html","id":"calendarization","dir":"Articles","previous_headings":"","what":"Calendarization","title":"Temporal disaggregation and Benchmarking methods based on JDemetra+ v3.x","text":"(Upcoming content)","code":""},{"path":"https://rjdverse.github.io/rjd3bench/articles/rjd3bench.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Temporal disaggregation and Benchmarking methods based on JDemetra+ v3.x","text":"Causey, B., Trager, M.L. (1981). Derivation Solution Benchmarking Problem: Trend Revision. Unpublished research notes, U.S. Census Bureau, Washington D.C. Available appendix Bozik Otto (1988). Chamberlin, G. (2010). Temporal disaggregation. ONS Economic & Labour Market Review. Di Fonzo, T., Marini, M. (2011). Newton’s Method Benchmarking Time Series according Growth Rates Preservation Principle. IMF WP/11/179. Daalmans, J., Di Fonzo, T., Mushkudiani, N., Bikker, R. (2018). Growth Rates Preservation (GRP) temporal benchmarking: Drawbacks alternative solutions. Survey Methodology, June 2018 Vol.44, .1, pp. 43-60 Statistics Canada, Catalogue . 12-001-X. Dagum, E. B., Cholette, P. . (2006): Benchmarking, Temporal Distribution Reconciliation Methods Time Series. Springer-Verlag, New York, Lecture notes Statistics. Quenneville, B., Fortier S., Chen Z.-G., Latendresse E. (2006). Recent Developments Benchmarking Annual Totals X12-ARIMA Statistics Canada. Statistics Canada, Working paper Time Series Research Analysis Centre. Quilis, EM. (2018). Temporal disaggregation economic time series - view trenches. Statistica Neerlandica, Wiley.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Jean Palate. Author. Corentin Lemasson. Maintainer, contributor. Tanguy Barthelemy. Contributor, artist.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Palate J (2025). rjd3bench: Interface 'JDemetra+ 3.x' time series analysis software. R package version 3.0.0.9000, https://github.com/rjdverse/rjd3bench.","code":"@Manual{,   title = {rjd3bench: Interface to 'JDemetra+ 3.x' time series analysis software},   author = {Jean Palate},   year = {2025},   note = {R package version 3.0.0.9000},   url = {https://github.com/rjdverse/rjd3bench}, }"},{"path":[]},{"path":"https://rjdverse.github.io/rjd3bench/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Interface to JDemetra+ 3.x time series analysis software","text":"rjd3bench provides variety methods temporal disaggregation & interpolation, benchmarking, reconciliation calendarization. Temporal disaggregation & interpolation: Chow-Lin, Fernandez Litterman Model-Based Denton Autoregressive Distributed Lag (ADL) models Benchmarking: Denton GRP (Growth Rate Preservation) Cubic Splines Cholette Reconciliation multivariate temporal disaggregation: Multivariate Cholette Calendarization","code":""},{"path":"https://rjdverse.github.io/rjd3bench/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Interface to JDemetra+ 3.x time series analysis software","text":"Running rjd3 packages requires Java 17 higher. set configuration R explained ","code":""},{"path":"https://rjdverse.github.io/rjd3bench/index.html","id":"latest-release","dir":"","previous_headings":"Installation","what":"Latest release","title":"Interface to JDemetra+ 3.x time series analysis software","text":"get current stable version (latest release): GitHub: r-universe:","code":"# install.packages(\"remotes\") remotes::install_github(\"rjdverse/rjd3bench@*release\") install.packages(\"rjd3bench\", repos = c(\"https://rjdverse.r-universe.dev\", \"https://cloud.r-project.org\"))"},{"path":"https://rjdverse.github.io/rjd3bench/index.html","id":"development-version","dir":"","previous_headings":"Installation","what":"Development version","title":"Interface to JDemetra+ 3.x time series analysis software","text":"get current development version GitHub:","code":"# install.packages(\"remotes\") remotes::install_github(\"rjdverse/rjd3bench\")"},{"path":"https://rjdverse.github.io/rjd3bench/index.html","id":"package-maintenance-and-contributing","dir":"","previous_headings":"","what":"Package Maintenance and contributing","title":"Interface to JDemetra+ 3.x time series analysis software","text":"contribution welcome done pull requests /issues. pull requests include updated tests updated documentation. functionality changed, docstrings added updated.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/index.html","id":"licensing","dir":"","previous_headings":"","what":"Licensing","title":"Interface to JDemetra+ 3.x time series analysis software","text":"code project licensed European Union Public Licence (EUPL).","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/adl_disaggregation.html","id":null,"dir":"Reference","previous_headings":"","what":"Temporal disaggregation & interpolation of a time series with ADL models — adl_disaggregation","title":"Temporal disaggregation & interpolation of a time series with ADL models — adl_disaggregation","text":"Temporal disaggregation & interpolation time series ADL models","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/adl_disaggregation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Temporal disaggregation & interpolation of a time series with ADL models — adl_disaggregation","text":"","code":"adl_disaggregation(   series,   constant = TRUE,   trend = FALSE,   indicators = NULL,   conversion = c(\"Sum\", \"Average\", \"Last\", \"First\", \"UserDefined\"),   conversion.obsposition = 1L,   phi = 0,   phi.fixed = FALSE,   phi.truncated = 0,   xar = c(\"FREE\", \"SAME\", \"NONE\") )"},{"path":"https://rjdverse.github.io/rjd3bench/reference/adl_disaggregation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Temporal disaggregation & interpolation of a time series with ADL models — adl_disaggregation","text":"xar","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/adl_disaggregation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Temporal disaggregation & interpolation of a time series with ADL models — adl_disaggregation","text":"","code":"# qna data, fernandez with/without quarterly indicator data(\"qna_data\") Y <- ts(qna_data$B1G_Y_data[,\"B1G_FF\"], frequency = 1, start = c(2009,1)) x <- ts(qna_data$TURN_Q_data[,\"TURN_INDEX_FF\"], frequency = 4, start = c(2009,1)) td1 <- adl_disaggregation(Y, indicators = x, xar = \"FREE\") td2 <- adl_disaggregation(Y, indicators = x, xar = \"SAME\")"},{"path":"https://rjdverse.github.io/rjd3bench/reference/calendarization.html","id":null,"dir":"Reference","previous_headings":"","what":"Calendarization — calendarization","title":"Calendarization — calendarization","text":"Based \"Calendarization splines state space models\" B. Quenneville, F.Picard S.Fortier Appl. Statistics (2013) 62, part 3, pp 371-399. State space implementation.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/calendarization.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calendarization — calendarization","text":"","code":"calendarization(   calendarobs,   freq,   start = NULL,   end = NULL,   dailyweights = NULL,   stde = FALSE )"},{"path":"https://rjdverse.github.io/rjd3bench/reference/calendarization.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calendarization — calendarization","text":"calendarobs Observations (list start, end, value). See example. freq Annual frequency. 0, daily series computed start Starting day calendarization. calendar obs (extrapolation) end Final day calendarization. calendar obs (extrapolation) dailyweights Daily weights. length requested series stde","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/calendarization.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calendarization — calendarization","text":"","code":"obs <- list(     list(start = \"1980-01-01\", end = \"1989-12-31\", value = 100),     list(start = \"1990-01-01\", end = \"1999-12-31\", value = -10),     list(start = \"2000-01-01\", end = \"2002-12-31\", value = 50)) cal <- calendarization(obs, 4, end = \"2003-12-31\", stde = TRUE) Q <- cal$rslt eQ <- cal$erslt"},{"path":"https://rjdverse.github.io/rjd3bench/reference/cholette.html","id":null,"dir":"Reference","previous_headings":"","what":"Benchmarking by means of the Cholette method — cholette","title":"Benchmarking by means of the Cholette method — cholette","text":"Cholette method based benchmarking methodology developed Statistics Canada. generalized method relying principle movement preservation encompasses benchmarking methods. Denton method (AFD PFD variants), well naive pro-rating method, emerge particular cases Cholette method. method widely used purpose benchmarking seasonally adjusted series among others.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/cholette.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Benchmarking by means of the Cholette method — cholette","text":"","code":"cholette(   s,   t,   rho = 1,   lambda = 1,   bias = c(\"None\", \"Additive\", \"Multiplicative\"),   conversion = c(\"Sum\", \"Average\", \"Last\", \"First\", \"UserDefined\"),   obsposition = 1L )"},{"path":"https://rjdverse.github.io/rjd3bench/reference/cholette.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Benchmarking by means of the Cholette method — cholette","text":"s Preliminary series. Mandatory. must class t. t Aggregation constraint. Mandatory. must either object class ts numeric vector. rho Numeric. Smoothing parameter whose value 0 1. See vignette information choice rho parameter. lambda Numeric. Adjustment model parameter. Typically, lambda = 1 proportional benchmarking; lambda = 0 additive benchmarking; lambda = 0.5 rho = 0 naive pro-rating method. See vignette information choice lambda parameter. bias Character. Bias correction factor. systematic bias considered default. See vignette details. conversion Conversion rule. Usually \"Sum\" \"Average\". Sum default. obsposition Position observation aggregated period (used \"UserDefined\" conversion).","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/cholette.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Benchmarking by means of the Cholette method — cholette","text":"benchmarked series returned","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/cholette.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Benchmarking by means of the Cholette method — cholette","text":"","code":"ym_true <- rjd3toolkit::Retail$RetailSalesTotal yq_true <- rjd3toolkit::aggregate(ym_true, 4) Y_full <- rjd3toolkit::aggregate(ym_true, 1)  Y <- window(Y_full, end = c(2009,1)) # say no benchmark yet for the year 2010 xm <- ym_true + rnorm(n = length(ym_true), mean = -5000, sd = 10000) xq <- rjd3toolkit::aggregate(xm, 4)  # Proportional benchmarking with a bias and some recommended value of rho for # monthly and quarterly series respectively (see vignette) cholette(s = xm, t = Y, rho = 0.9, lambda = 1, bias = \"Multiplicative\") #>           Jan      Feb      Mar      Apr      May      Jun      Jul      Aug #> 1992 129476.7 136648.0 153798.2 128168.5 149945.8 149472.7 149966.0 147154.3 #> 1993 118020.0 129407.5 153633.1 165769.0 155842.0 169681.3 170375.9 152449.4 #> 1994 146559.3 139242.4 160567.4 183125.2 180109.3 183750.0 192356.8 185963.3 #> 1995 168026.2 154400.0 174018.3 174208.7 185658.3 193739.9 208033.8 191101.5 #> 1996 162077.2 169321.0 189949.7 190290.1 209911.8 172315.0 223221.7 199740.3 #> 1997 178407.9 166368.5 194661.6 211168.9 214353.3 211887.5 192828.3 198328.2 #> 1998 192373.0 188988.4 205934.8 212688.5 218588.5 238188.1 228130.9 220973.0 #> 1999 189464.9 197564.3 219738.3 224492.1 241137.5 240667.3 230517.9 239912.6 #> 2000 211721.8 226155.6 251018.2 233883.7 256733.7 244434.3 244521.9 259355.6 #> 2001 212618.4 225048.9 246313.9 250789.0 285228.4 259372.2 229365.1 263538.2 #> 2002 233256.4 228672.4 258283.0 265195.1 271823.2 258052.0 272455.7 270059.7 #> 2003 247050.8 223976.0 260606.8 273415.2 280184.6 267081.4 268199.8 301069.9 #> 2004 255135.4 235891.2 301436.7 286960.0 296236.9 277132.2 288578.9 304494.1 #> 2005 272752.9 247398.5 318870.3 301975.6 317625.4 303019.7 312937.7 314184.6 #> 2006 279289.3 298280.5 339735.9 327479.6 351140.4 328406.1 314512.0 337114.9 #> 2007 305920.3 290012.6 348811.2 312898.7 370067.4 340137.8 336472.8 351583.8 #> 2008 304973.1 309272.6 344529.3 343162.1 364451.8 336798.2 360204.1 344387.4 #> 2009 270136.1 245900.9 320382.2 283379.8 307724.1 318024.6 299791.2 324293.8 #> 2010 293445.2 276841.6 326776.5 324356.5 333414.3 316459.3 341257.4 333610.3 #>           Sep      Oct      Nov      Dec #> 1992 155051.8 178175.0 138725.9 199133.0 #> 1993 168943.6 185889.4 171506.9 200729.8 #> 1994 175437.6 160318.1 182532.3 220059.2 #> 1995 185453.5 182533.0 171299.7 234031.1 #> 1996 190654.3 212495.5 196704.3 249984.2 #> 1997 205429.8 225088.4 210845.4 264635.3 #> 1998 210789.3 210844.7 225354.1 234251.7 #> 1999 242913.1 226281.0 248558.1 307308.8 #> 2000 244470.9 253159.1 266928.1 296373.1 #> 2001 241756.2 280943.9 262574.8 310175.9 #> 2002 258019.5 263857.4 252735.7 301911.9 #> 2003 269775.2 280398.1 282511.8 313884.6 #> 2004 289701.7 288167.2 291494.5 365201.3 #> 2005 308033.9 303191.3 321199.4 375501.9 #> 2006 332923.8 301267.4 309445.3 360541.0 #> 2007 305348.7 315480.5 329485.7 399578.4 #> 2008 313089.9 289414.9 302889.3 339760.2 #> 2009 292279.6 310125.5 312314.6 354118.6 #> 2010 309711.9 329990.6 320849.7 399381.2 cholette(s = xq, t = Y, rho = 0.729, lambda = 1, bias = \"Multiplicative\") #>           Qtr1      Qtr2      Qtr3      Qtr4 #> 1992  419922.5  427571.6  452171.5  516050.4 #> 1993  401071.9  491346.5  491779.3  558050.4 #> 1994  446249.3  546841.9  553681.0  563248.7 #> 1995  496256.2  553656.2  584677.7  587914.0 #> 1996  521541.3  572617.0  613590.3  658916.4 #> 1997  539447.6  637402.9  596531.7  700620.8 #> 1998  586936.4  669247.4  659893.4  671027.8 #> 1999  607169.0  706856.4  713573.3  780957.3 #> 2000  689086.9  734592.6  747887.5  817189.0 #> 2001  683526.2  795636.6  735198.0  853364.2 #> 2002  720763.4  794924.3  800115.2  818519.1 #> 2003  731115.4  820654.4  839337.8  877046.4 #> 2004  792786.5  860452.3  882681.4  944509.7 #> 2005  839099.7  922693.7  935140.2  999757.4 #> 2006  916979.4 1006663.3  984530.6  971962.7 #> 2007  944660.1 1023404.0  993693.6 1044040.4 #> 2008  959253.8 1044433.7 1017472.2  931773.2 #> 2009  836211.4  909092.3  916442.5  976724.8 #> 2010  897068.5  974223.5  984570.2 1050228.0  # Proportional benchmarking with no bias xm_no_bias <- ym_true + rnorm(n = length(ym_true), mean = 0, sd = 10000) cholette(s = xm_no_bias, t = Y, rho = 0.9, lambda = 1) #>           Jan      Feb      Mar      Apr      May      Jun      Jul      Aug #> 1992 119121.9 140636.2 128740.8 150099.9 148247.9 145534.7 161629.8 166241.0 #> 1993 149904.9 120705.2 167194.6 158848.1 162866.4 167408.6 165965.9 155897.2 #> 1994 138568.1 151359.4 171559.4 167696.7 193743.5 183507.3 161958.2 185693.5 #> 1995 148940.5 154180.2 183716.4 176169.5 167115.2 188427.0 181804.2 190899.1 #> 1996 162317.3 182060.7 180887.0 195746.7 207305.4 199006.0 206977.3 193632.5 #> 1997 178028.1 167633.3 207674.8 214410.3 195695.6 190759.6 217009.5 217664.0 #> 1998 199148.9 185647.4 203818.0 218169.2 240506.6 239223.1 201336.9 210538.1 #> 1999 195572.2 209239.9 225295.8 214145.8 236625.4 240381.7 237454.4 252075.6 #> 2000 225549.7 228830.7 258370.9 247954.3 236478.1 265835.3 241754.4 259520.4 #> 2001 235229.8 221680.2 274386.2 247973.5 254866.8 248999.9 268458.5 265290.6 #> 2002 225729.1 229206.8 268687.7 265534.9 280053.9 250566.3 278611.8 266473.5 #> 2003 258892.2 232202.6 275076.8 250314.2 275423.6 285051.9 280666.3 290311.0 #> 2004 265567.4 258313.8 283259.6 282465.4 307370.2 291475.0 289492.2 290878.8 #> 2005 269678.9 255526.4 306153.7 294504.0 317050.5 332214.7 306830.4 318737.2 #> 2006 282723.0 300777.3 319382.4 308967.9 350245.9 318557.2 316775.1 348378.9 #> 2007 289701.7 283956.4 331158.9 334769.1 358831.8 342583.4 315591.3 357262.1 #> 2008 299270.6 281070.9 344901.8 327810.1 342959.2 345583.0 358716.5 353129.8 #> 2009 275977.1 259670.3 293091.0 301154.1 298003.0 300484.1 324880.5 310834.5 #> 2010 276945.6 298910.6 333661.7 344259.9 338012.8 319123.4 314217.2 330575.8 #>           Sep      Oct      Nov      Dec #> 1992 133039.6 148719.1 169639.3 204065.8 #> 1993 154673.5 152685.7 163459.1 222638.7 #> 1994 175934.0 172131.1 165290.4 242579.4 #> 1995 198515.0 202920.9 197686.2 232129.9 #> 1996 190460.1 214878.6 198757.4 234635.8 #> 1997 222067.7 206303.2 196732.4 260024.6 #> 1998 196455.1 224981.8 199614.5 267665.2 #> 1999 228596.2 251443.7 223647.5 294077.7 #> 2000 255553.9 233331.7 240487.7 295088.8 #> 2001 231111.2 262632.1 267591.8 289504.6 #> 2002 233135.7 252239.7 270430.5 313652.0 #> 2003 261313.5 267023.4 265122.8 326755.7 #> 2004 280833.4 288518.4 291437.6 350818.3 #> 2005 318435.3 287225.1 322116.1 368218.8 #> 2006 334432.4 309084.6 308714.8 382096.4 #> 2007 318913.1 336661.4 340368.1 396000.6 #> 2008 310801.2 323780.2 317770.7 347138.9 #> 2009 292401.1 313564.0 308950.1 359461.2 #> 2010 294817.5 323822.7 333537.6 408230.0  # Additive benchmarking cholette(s = xm, t = Y, rho = 0.9, lambda = 0, bias = \"Additive\") #>           Jan      Feb      Mar      Apr      May      Jun      Jul      Aug #> 1992 140343.1 144085.5 157969.5 130765.6 149960.3 147963.6 147277.1 143755.5 #> 1993 116944.4 128760.1 152796.1 165069.9 156028.9 169737.2 170727.0 153765.2 #> 1994 148230.6 141099.9 161398.4 182890.0 179900.6 183312.0 191522.6 185346.7 #> 1995 167978.1 154665.4 173936.6 174185.9 185545.4 193610.5 207831.1 191128.7 #> 1996 162516.4 169696.0 190077.6 190417.2 209752.7 172750.4 222822.0 199753.2 #> 1997 179079.3 167408.9 194963.3 211006.9 214095.6 211702.9 193200.3 198539.9 #> 1998 192729.1 189413.6 206054.3 212714.9 218548.7 237942.9 228014.5 220911.3 #> 1999 188996.1 197086.1 219481.7 224352.7 241251.4 240844.5 230681.5 240198.7 #> 2000 213115.4 227297.7 251283.5 234824.2 256613.2 244803.3 244790.1 258808.4 #> 2001 212753.0 224800.8 245857.4 250445.4 285047.8 259319.0 229298.0 263727.1 #> 2002 233929.5 229507.5 258551.8 265244.0 271632.1 258203.3 272135.7 269772.8 #> 2003 247145.1 224420.1 260476.7 273185.9 279966.4 267038.5 268204.7 300954.8 #> 2004 255402.4 236323.1 301362.0 287011.5 296199.5 277319.3 288652.2 304372.4 #> 2005 273395.5 248675.2 318545.8 302070.8 317345.3 303141.3 312826.8 314074.2 #> 2006 280391.8 298932.5 339387.7 327452.4 350602.4 328360.0 314698.7 336876.1 #> 2007 305439.8 289343.4 348574.1 312376.7 370336.3 340115.7 336487.0 351889.8 #> 2008 305844.6 310336.7 345441.6 344004.4 364874.4 337356.5 360082.5 344134.8 #> 2009 267910.3 243600.9 316192.5 280059.0 304260.5 315063.9 298309.4 323710.8 #> 2010 306800.3 293733.9 345551.9 345782.4 357007.4 342486.3 368711.7 362918.4 #>           Sep      Oct      Nov      Dec #> 1992 150937.7 173158.8 135324.6 194174.8 #> 1993 169756.5 186091.3 172314.4 200257.0 #> 1994 175185.4 160552.2 182032.5 218550.0 #> 1995 185572.1 182706.9 171601.2 233742.1 #> 1996 190858.7 212278.0 196842.7 248900.1 #> 1997 205438.6 224571.9 210726.6 263268.9 #> 1998 210752.7 210751.3 225196.0 234075.8 #> 1999 243255.6 226751.8 248953.2 306702.7 #> 2000 244474.7 252641.1 265776.9 294327.6 #> 2001 241954.0 281317.6 262949.1 310255.7 #> 2002 258060.9 263689.3 252826.5 300768.6 #> 2003 269865.2 280474.5 282603.9 313818.2 #> 2004 289812.0 288337.3 291650.0 363988.2 #> 2005 308132.3 303469.5 321044.4 373969.8 #> 2006 332716.5 301337.7 309294.1 360086.1 #> 2007 305172.9 315596.6 329930.1 400535.5 #> 2008 312951.7 289190.7 301718.0 336997.0 #> 2009 294207.5 313871.7 318640.4 362644.2 #> 2010 341001.0 362288.2 354559.6 432789.9  # Denton PFD cholette(s = xm, t = Y, rho = 1, lambda = 1) #>           Jan      Feb      Mar      Apr      May      Jun      Jul      Aug #> 1992 129880.4 136947.1 154010.9 128260.9 149967.6 149425.7 149865.8 147018.4 #> 1993 117923.0 129325.2 153558.6 165712.9 155812.8 169672.7 170390.2 152481.9 #> 1994 146643.5 139322.0 160645.3 183188.9 180144.5 183755.4 192331.1 185913.5 #> 1995 168030.8 154432.3 174068.6 174259.2 185702.9 193770.3 208045.5 191091.3 #> 1996 162007.0 169247.2 189876.1 190232.7 209872.0 172304.2 223236.7 199777.7 #> 1997 178437.0 166379.2 194657.7 211151.8 214328.5 211860.5 192805.3 198307.4 #> 1998 192484.1 189127.0 206093.6 212838.5 218710.0 238269.3 228147.7 220925.1 #> 1999 189261.6 197361.0 219536.8 224324.7 241013.6 240608.8 230530.5 240000.7 #> 2000 211816.2 226203.1 251041.6 233897.9 256744.5 244441.9 244520.4 259336.5 #> 2001 212674.3 225142.9 246419.2 250874.6 285288.0 259384.0 229341.8 263487.1 #> 2002 233124.7 228537.6 258150.1 265095.5 271767.0 258043.2 272487.5 270125.0 #> 2003 247209.9 224120.7 260755.4 273534.2 280258.9 267102.7 268173.8 300994.3 #> 2004 254989.9 235768.1 301309.5 286874.8 296190.9 277129.4 288616.7 304571.4 #> 2005 272771.9 247382.7 318820.5 301917.3 317564.0 302970.9 312903.5 314171.8 #> 2006 279433.0 298454.5 339929.3 327638.0 351259.4 328456.1 314493.8 337023.6 #> 2007 305828.6 289972.4 348805.1 312910.1 370099.0 340167.7 336501.4 351612.6 #> 2008 304873.6 309143.0 344393.2 343060.5 364395.8 336798.7 360257.9 344479.4 #> 2009 270138.6 245865.6 320297.3 283285.8 307614.0 317917.7 299712.5 324247.3 #> 2010 293816.5 277293.7 327418.4 325090.5 334258.4 317337.0 342278.1 334673.6 #>           Sep      Oct      Nov      Dec #> 1992 154882.0 177965.2 138568.2 198923.7 #> 1993 168995.1 185959.7 171584.7 200831.3 #> 1994 175373.9 160251.9 182457.1 219994.0 #> 1995 185424.4 182488.3 171245.5 233944.8 #> 1996 190708.5 212568.9 196774.4 250059.6 #> 1997 205414.6 225085.2 210866.8 264709.0 #> 1998 210683.1 210685.0 225139.6 234002.1 #> 1999 243071.2 226475.6 248796.7 307574.8 #> 2000 244435.9 253106.1 266869.2 296342.8 #> 2001 241694.7 280866.4 262493.3 310058.5 #> 2002 258106.5 263963.9 252851.7 302069.2 #> 2003 269671.6 280264.0 282360.2 313708.4 #> 2004 289800.4 288277.5 291600.9 365300.6 #> 2005 308046.8 303232.1 321274.9 375634.5 #> 2006 332771.1 301088.9 309247.9 360340.4 #> 2007 305366.2 315494.9 329490.9 399549.2 #> 2008 313196.7 289519.3 302985.5 339829.4 #> 2009 292288.6 310203.2 312478.4 354422.1 #> 2010 310753.7 331153.2 322026.0 400896.8  # Pro-rating cholette(s = xm, t = Y, rho = 0, lambda = 0.5) #>           Jan      Feb      Mar      Apr      May      Jun      Jul      Aug #> 1992 130111.6 137182.1 154255.0 128437.6 150133.7 149540.0 149918.0 146997.6 #> 1993 118411.7 129750.6 153938.2 165994.5 155964.7 169722.7 170332.8 152341.6 #> 1994 145860.1 138566.6 159800.6 182307.0 179414.9 183210.0 192030.9 185949.1 #> 1995 166171.0 153200.4 173168.3 173789.0 185598.4 194004.3 208584.4 191770.4 #> 1996 163108.6 170222.3 190766.0 190912.3 210379.5 172514.4 223233.7 199519.4 #> 1997 178761.7 166473.9 194570.8 210900.7 213977.2 211481.1 192487.3 198061.6 #> 1998 190028.4 187092.4 204302.5 211444.5 217762.5 237784.4 228227.5 221548.1 #> 1999 190262.1 198824.8 221460.2 226393.5 243129.1 242380.4 231680.9 240412.0 #> 2000 214740.9 227775.7 251390.1 233242.5 255269.1 242644.5 242637.6 257575.6 #> 2001 208625.7 222431.7 244952.6 250648.1 286156.8 260863.1 230984.8 265478.7 #> 2002 236359.4 230540.7 259286.0 265320.4 271253.5 257060.3 271135.5 268690.3 #> 2003 244283.0 222206.3 259310.5 272741.9 280081.2 267431.5 268901.2 302139.3 #> 2004 256733.0 237127.5 302715.2 287886.4 296887.0 277444.4 288584.6 304146.4 #> 2005 274049.4 248208.8 319498.9 302244.6 317627.0 302812.7 312563.6 313704.1 #> 2006 276755.6 295799.1 337231.5 325456.4 349477.9 327421.0 314206.2 337573.5 #> 2007 303556.4 288849.6 348497.4 313350.5 371231.1 341510.2 337890.3 352881.4 #> 2008 309147.3 312330.8 346783.7 344409.9 364862.0 336460.0 359193.4 342912.3 #> 2009 270206.6 245912.2 320339.4 283308.4 307624.1 317915.2 299699.5 324223.7 #> 2010 287409.1 271246.6 320278.3 318001.0 326969.0 310416.7 334813.9 327375.2 #>           Sep      Oct      Nov      Dec #> 1992 154773.2 177727.1 138282.9 198357.3 #> 1993 168748.3 185596.6 171174.2 200272.1 #> 1994 175773.7 161003.8 183808.2 222296.2 #> 1995 186190.1 183277.8 171956.4 234793.3 #> 1996 190210.2 211724.8 195717.4 248356.4 #> 1997 205300.8 225179.4 211226.9 265581.6 #> 1998 211815.4 212372.8 227555.7 237170.9 #> 1999 242468.0 224758.7 245440.7 301345.6 #> 2000 243326.7 252852.8 267909.9 299390.5 #> 2001 243319.9 282205.9 262894.3 309163.3 #> 2002 256850.5 262997.9 252429.9 302397.5 #> 2003 270873.1 281584.0 283645.5 314956.5 #> 2004 289013.0 287102.9 290006.9 362782.6 #> 2005 307514.0 302682.4 320715.8 375069.8 #> 2006 334272.9 303417.1 312732.1 365792.7 #> 2007 306087.2 315648.4 328823.0 397472.5 #> 2008 311377.3 287560.3 300729.5 337166.4 #> 2009 292260.5 310167.7 312438.9 354374.9 #> 2010 303977.0 323931.5 315003.4 392154.3"},{"path":"https://rjdverse.github.io/rjd3bench/reference/cubicspline.html","id":null,"dir":"Reference","previous_headings":"","what":"Benchmarking by means of cubic splines — cubicspline","title":"Benchmarking by means of cubic splines — cubicspline","text":"Cubic splines piecewise cubic functions linked together way guarantee smoothness data points. Additivity constraints added benchmarking purpose sub-period estimates derived spline. sub-period indicator (preliminary series) used, cubic splines longer drawn based low frequency data Benchmark--Indicator (BI ratio) one smoothed. Sub- period estimates simply product smoothed high frequency BI ratio indicator.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/cubicspline.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Benchmarking by means of cubic splines — cubicspline","text":"","code":"cubicspline(   s = NULL,   t,   nfreq = 4L,   conversion = c(\"Sum\", \"Average\", \"Last\", \"First\", \"UserDefined\"),   obsposition = 1L )"},{"path":"https://rjdverse.github.io/rjd3bench/reference/cubicspline.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Benchmarking by means of cubic splines — cubicspline","text":"s Preliminary series. NULL, must class t. t Aggregation constraint. Mandatory. must either object class ts numeric vector. nfreq Integer. Annual frequency benchmarked series. Used preliminary series provided. conversion Conversion rule. Usually \"Sum\" \"Average\". Sum default. obsposition Integer. Postion observation aggregated period (used \"UserDefined\" conversion)","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/cubicspline.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Benchmarking by means of cubic splines — cubicspline","text":"benchmarked series returned","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/cubicspline.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Benchmarking by means of cubic splines — cubicspline","text":"","code":"data(\"qna_data\") Y <- ts(qna_data$B1G_Y_data[,\"B1G_FF\"], frequency = 1, start = c(2009,1))  # cubic spline without preliminary series y1 <- cubicspline(t = Y, nfreq = 4L)  # cubic spline with preliminary series x1 <- y1 + rnorm(n = length(y1), mean = 0, sd = 10) cubicspline(s = x1, t = Y) #>          Qtr1     Qtr2     Qtr3     Qtr4 #> 2009 4400.337 4385.278 4399.957 4368.828 #> 2010 4363.614 4391.251 4439.493 4525.742 #> 2011 4639.636 4712.704 4745.943 4757.717 #> 2012 4743.745 4711.949 4701.552 4692.454 #> 2013 4675.787 4673.251 4683.889 4680.572 #> 2014 4714.546 4745.824 4765.462 4782.169 #> 2015 4801.393 4797.330 4832.282 4862.994 #> 2016 4906.571 4893.879 4934.591 4943.359 #> 2017 4952.752 4979.728 5057.345 5160.075 #> 2018 5275.700 5404.686 5494.949 5592.064 #> 2019 5630.302 5665.310 5641.002 5577.587 #> 2020 5470.537 5403.901 5358.985 5333.077  # cubic splines used for temporal disaggregation x2 <- ts(qna_data$TURN_Q_data[,\"TURN_INDEX_FF\"], frequency = 4, start = c(2009,1)) cubicspline(s = x2, t = Y) #>          Qtr1     Qtr2     Qtr3     Qtr4 #> 2009 3817.265 4655.940 4125.907 4955.289 #> 2010 3700.042 4651.986 4059.082 5308.990 #> 2011 3869.960 4971.484 4311.150 5703.406 #> 2012 4147.811 5013.761 4419.430 5268.698 #> 2013 4159.471 4867.414 4371.355 5315.259 #> 2014 4368.250 4889.973 4383.173 5366.604 #> 2015 4219.172 5090.938 4499.862 5484.029 #> 2016 4323.788 5190.106 4608.648 5555.858 #> 2017 4571.106 5296.208 4556.676 5725.911 #> 2018 4745.996 5623.545 5073.312 6324.547 #> 2019 5083.042 5847.280 5201.402 6382.476 #> 2020 5135.178 4920.197 5120.096 6391.030 #> 2021 5361.533 6291.365 5489.010 6962.494"},{"path":"https://rjdverse.github.io/rjd3bench/reference/denton.html","id":null,"dir":"Reference","previous_headings":"","what":"Benchmarking by means of the Denton method. — denton","title":"Benchmarking by means of the Denton method. — denton","text":"Denton method relies principle movement preservation. exist variants corresponding different definitions movement preservation: additive first difference (AFD), proportional first difference (PFD), additive second difference (ASD), proportional second difference (PSD), etc. default widely used Denton PFD method.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/denton.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Benchmarking by means of the Denton method. — denton","text":"","code":"denton(   s = NULL,   t,   d = 1L,   mul = TRUE,   nfreq = 4L,   modified = TRUE,   conversion = c(\"Sum\", \"Average\", \"Last\", \"First\", \"UserDefined\"),   obsposition = 1L,   nbcsts = 0L,   nfcsts = 0L )"},{"path":"https://rjdverse.github.io/rjd3bench/reference/denton.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Benchmarking by means of the Denton method. — denton","text":"s Preliminary series. NULL, must class t. t Aggregation constraint. Mandatory. must either object class ts numeric vector. d Differencing order. 1 default. mul Multiplicative additive benchmarking. Multiplicative default. nfreq Annual frequency disaggregated variable. Used disaggregated series provided. modified Modified (TRUE) unmodified (FALSE) Denton. Modified default. conversion Conversion rule. Usually \"Sum\" \"Average\". Sum default. obsposition Position observation aggregated period (used \"UserDefined\" conversion). nbcsts Number backcast periods. Ignored preliminary series provided. (yet implemented) nfcsts Number forecast periods. Ignored preliminary series provided. (yet implemented)","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/denton.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Benchmarking by means of the Denton method. — denton","text":"benchmarked series returned","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/denton.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Benchmarking by means of the Denton method. — denton","text":"","code":"Y <- rjd3toolkit::aggregate(rjd3toolkit::Retail$RetailSalesTotal, 1)  # denton PFD without a preliminary series y1 <- denton(t = Y, nfreq = 4) print(y1) #>           Qtr1      Qtr2      Qtr3      Qtr4 #> 1992  448459.8  450647.5  455022.8  461585.9 #> 1993  470336.7  479927.1  490357.2  501627.0 #> 1994  513736.5  524087.8  532680.9  539515.8 #> 1995  544592.4  551036.5  558848.0  568027.0 #> 1996  578573.3  588029.0  596394.1  603668.5 #> 1997  609852.3  615785.2  621467.2  626898.3 #> 1998  632078.6  640029.7  650751.8  664244.9 #> 1999  680508.8  695666.5  709717.8  722662.8 #> 2000  734501.5  744312.0  752094.2  757848.3 #> 2001  761574.1  765207.3  768747.8  772195.7 #> 2002  775550.9  780104.8  785857.5  792808.8 #> 2003  800958.8  810650.7  821884.4  834660.1 #> 2004  848977.5  863156.5  877197.0  891099.0 #> 2005  904862.4  918091.9  930787.5  942949.2 #> 2006  954576.9  965410.8  975451.0  984697.4 #> 2007  993150.0  999850.8 1004799.9 1007997.3 #> 2008 1009442.9 1001537.3  984280.4  957672.4 #> 2009  921713.2  902491.3  900006.8  914259.6 #> 2010  945249.8  968492.5  983987.6  991735.1  # denton PFD without a preliminary series and conversion = \"Average\" denton(t = Y, nfreq = 4, conversion = \"Average\") #>         Qtr1    Qtr2    Qtr3    Qtr4 #> 1992 1793839 1802590 1820091 1846344 #> 1993 1881347 1919708 1961429 2006508 #> 1994 2054946 2096351 2130724 2158063 #> 1995 2178370 2204146 2235392 2272108 #> 1996 2314293 2352116 2385576 2414674 #> 1997 2439409 2463141 2485869 2507593 #> 1998 2528314 2560119 2603007 2656980 #> 1999 2722035 2782666 2838871 2890651 #> 2000 2938006 2977248 3008377 3031393 #> 2001 3046297 3060829 3074991 3088783 #> 2002 3102204 3120419 3143430 3171235 #> 2003 3203835 3242603 3287538 3338640 #> 2004 3395910 3452626 3508788 3564396 #> 2005 3619450 3672368 3723150 3771797 #> 2006 3818307 3861643 3901804 3938789 #> 2007 3972600 3999403 4019200 4031989 #> 2008 4037771 4006149 3937122 3830690 #> 2009 3686853 3609965 3600027 3657039 #> 2010 3780999 3873970 3935950 3966940  # denton PFD with a preliminary series x <- y1 + rnorm(n = length(y1), mean = 0, sd = 10000) denton(s = x, t = Y) #>           Qtr1      Qtr2      Qtr3      Qtr4 #> 1992  452252.4  431594.5  475592.7  456276.4 #> 1993  464975.1  478932.7  483960.9  514379.3 #> 1994  518589.7  514922.4  544945.1  531563.8 #> 1995  538353.4  550675.2  560070.4  573405.0 #> 1996  578870.7  600143.2  580999.0  606652.1 #> 1997  610164.7  613745.5  629293.1  620799.7 #> 1998  631687.8  639941.5  651952.2  663523.5 #> 1999  667225.9  690848.6  714652.8  735828.8 #> 2000  730899.3  756724.9  745494.5  755637.4 #> 2001  754324.1  760258.1  774506.7  778636.1 #> 2002  769589.6  773817.5  778185.6  812729.3 #> 2003  806202.6  814316.4  813723.1  833911.8 #> 2004  841584.0  874817.2  867352.0  896676.8 #> 2005  908245.6  908998.7  954678.6  924768.0 #> 2006  949567.4  962146.7  972408.7  996013.2 #> 2007  999617.3 1002049.5 1000039.9 1004091.4 #> 2008  999962.4 1002485.6  979654.1  970830.8 #> 2009  913661.4  906649.3  901955.8  916204.5 #> 2010  950510.3  948778.9  990446.3  999729.4  # denton AFD with a preliminary series denton(s = x, t = Y, mul = FALSE) #>           Qtr1      Qtr2      Qtr3      Qtr4 #> 1992  452254.0  431266.1  475891.5  456304.4 #> 1993  465013.3  478952.1  483988.9  514293.6 #> 1994  518674.6  515075.8  544865.8  531404.8 #> 1995  538073.7  550590.5  560194.9  573644.9 #> 1996  579072.0  599971.4  581257.0  606364.6 #> 1997  610023.9  613739.5  629348.8  620890.8 #> 1998  631716.9  639937.6  651951.8  663498.7 #> 1999  667029.7  690782.8  714741.3  736002.2 #> 2000  730954.2  756758.3  745459.5  755584.0 #> 2001  754293.5  760253.7  774525.6  778652.2 #> 2002  769595.5  773820.9  778201.6  812704.0 #> 2003  806278.0  814376.2  813708.0  833791.8 #> 2004  841352.1  874804.1  867388.8  896885.0 #> 2005  908442.3  909176.7  954340.9  924731.0 #> 2006  949418.2  962111.0  972506.4  996100.4 #> 2007  999651.1 1002037.9 1000031.2 1004077.8 #> 2008 1000109.3 1002713.2  979582.9  970527.6 #> 2009  913319.0  906597.8  902153.1  916401.1 #> 2010  950519.9  948870.0  990394.1  999681.0"},{"path":"https://rjdverse.github.io/rjd3bench/reference/denton_modelbased.html","id":null,"dir":"Reference","previous_headings":"","what":"Temporal disaggregation & interpolation of a time series by model-based Denton proportional method — denton_modelbased","title":"Temporal disaggregation & interpolation of a time series by model-based Denton proportional method — denton_modelbased","text":"Denton proportional method can expressed statistical model State space representation (see documentation definition states). approach interesting allows flexibility model inclusion outliers (level shift Benchmark Indicator ratio) otherwise induce unintended wave effects standard Denton method. Outliers intensity defined changing value 'innovation variances'.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/denton_modelbased.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Temporal disaggregation & interpolation of a time series by model-based Denton proportional method — denton_modelbased","text":"","code":"denton_modelbased(   series,   indicator,   differencing = 1L,   conversion = c(\"Sum\", \"Average\", \"Last\", \"First\", \"UserDefined\"),   conversion.obsposition = 1L,   outliers = NULL,   fixedBIratios = NULL )"},{"path":"https://rjdverse.github.io/rjd3bench/reference/denton_modelbased.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Temporal disaggregation & interpolation of a time series by model-based Denton proportional method — denton_modelbased","text":"series Aggregation constraint. Mandatory. must either object class ts numeric vector. indicator High-frequency indicator. Mandatory. must class series differencing implemented yet. Keep equals 1 (Denton PFD method). conversion Conversion rule. Usually \"Sum\" \"Average\". Sum default. conversion.obsposition Position observation aggregated period (used \"UserDefined\" conversion) outliers list structured definition outlier periods intensity. period must submitted first format YYYY-MM-DD enclosed quotation marks. must followed equal sign intensity outlier, defined relative value 'innovation variances' (1= normal situation) fixedBIratios list structured definition periods BI ratios must fixed. period must submitted first format YYYY-MM-DD enclosed quotation marks. must followed equal sign value BI ratio.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/denton_modelbased.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Temporal disaggregation & interpolation of a time series by model-based Denton proportional method — denton_modelbased","text":"object class 'JD3MBDenton'","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/denton_modelbased.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Temporal disaggregation & interpolation of a time series by model-based Denton proportional method — denton_modelbased","text":"","code":"# Retail data, monthly indicator Y <- rjd3toolkit::aggregate(rjd3toolkit::Retail$RetailSalesTotal, 1) x <- rjd3toolkit::aggregate(rjd3toolkit::Retail$FoodAndBeverageStores, 4) td <- denton_modelbased(Y, x, outliers = list(\"2000-01-01\" = 100, \"2005-07-01\" = 100)) y <- td$estimation$edisagg  # qna data, quarterly indicator data(\"qna_data\") Y <- ts(qna_data$B1G_Y_data[,\"B1G_FF\"], frequency = 1, start = c(2009,1)) x <- ts(qna_data$TURN_Q_data[,\"TURN_INDEX_FF\"], frequency = 4, start = c(2009,1))  td1 <- denton_modelbased(Y, x) td2 <- denton_modelbased(Y, x, outliers = list(\"2020-04-01\" = 100), fixedBIratios = list(\"2021-04-01\" = 39.0))  bi1 <- td1$estimation$biratio bi2 <- td2$estimation$biratio y1 <- td1$estimation$disagg y2 <- td2$estimation$disagg if (FALSE) { # \\dontrun{ ts.plot(bi1,bi2,gpars = list(col = c(\"red\",\"blue\"))) ts.plot(y1,y2,gpars = list(col = c(\"red\",\"blue\"))) } # }"},{"path":"https://rjdverse.github.io/rjd3bench/reference/denton_raw.html","id":null,"dir":"Reference","previous_headings":"","what":"Benchmarking of an atypical frequency series by means of the Denton method. — denton_raw","title":"Benchmarking of an atypical frequency series by means of the Denton method. — denton_raw","text":"Denton method relies principle movement preservation. exist variants corresponding different definitions movement preservation: additive first difference (AFD), proportional first difference (PFD), additive second difference (ASD), proportional second difference (PSD), etc. default widely used Denton PFD method. \"raw\" function extends denton() function way can deal frequency ratio preliminary series aggregation constraint.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/denton_raw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Benchmarking of an atypical frequency series by means of the Denton method. — denton_raw","text":"","code":"denton_raw(   s = NULL,   t,   freqratio,   d = 1L,   mul = TRUE,   modified = TRUE,   conversion = c(\"Sum\", \"Average\", \"Last\", \"First\", \"UserDefined\"),   obsposition = 1L,   startoffset = 0L,   nbcsts = 0L,   nfcsts = 0L )"},{"path":"https://rjdverse.github.io/rjd3bench/reference/denton_raw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Benchmarking of an atypical frequency series by means of the Denton method. — denton_raw","text":"s Preliminary series. NULL, must numeric vector. t Aggregation constraint. Mandatory. must numeric vector. freqratio Frequency ratio benchmarked series aggregation constraint. Mandatory. must positive integer. d Differencing order. 1 default. mul Multiplicative additive benchmarking. Multiplicative default. modified Modified (TRUE) unmodified (FALSE) Denton. Modified default. conversion Conversion rule. Usually \"Sum\" \"Average\". Sum default. obsposition Position observation aggregated period (used \"UserDefined\" conversion). startoffset Number initial observations indicator(s) series prior period covered low-frequency series. Must 0 positive integer. 0 default. Ignored preliminary series provided. nbcsts Number backcast periods. Ignored preliminary series provided. (yet implemented) nfcsts Number forecast periods. Ignored preliminary series provided. (yet implemented)","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/denton_raw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Benchmarking of an atypical frequency series by means of the Denton method. — denton_raw","text":"Numeric vector. benchmarked series.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/denton_raw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Benchmarking of an atypical frequency series by means of the Denton method. — denton_raw","text":"","code":"Y <- c(500,510,525,520) x <- c(97, 98, 98.5, 99.5, 104,        99, 100, 100.5, 101, 105.5,        103, 104.5, 103.5, 104.5, 109,        104, 107, 103, 108, 113,        110)  # denton PFD (for example, x and Y could be annual and quiquennal series respectively) denton_raw(x, Y, freqratio = 5) #>  [1]  97.53918  98.55612  99.08195 100.12282 104.69992  99.72518 100.77674 #>  [8] 101.30957 101.82703 106.36148 103.82195 105.14453 103.77995 104.24995 #> [15] 108.00362 102.16847 104.38553  99.95494 104.42926 109.06180 106.16635  # denton AFD denton_raw(x, Y, freqratio = 5, mul = FALSE) #>  [1]  97.55184  98.56388  99.08796 100.12408 104.67224  99.73243 100.77942 #>  [8] 101.31321 101.83378 106.34115 103.83532 105.14857 103.78091 104.23234 #> [15] 108.00286 102.09247 104.36416  99.81792 104.45377 109.27169 106.27169  # denton PFD without indicator denton_raw(t = Y, freqratio = 2, conversion = \"Average\") #> [1] 498.75 501.25 506.25 513.75 523.75 526.25 521.25 518.75  # denton PFD with/without an offset and conversion = \"Last\" x2 <- c(485,         490, 492.5, 497.5, 520, 495,         500, 502.5, 505, 527.5, 515,         522.5, 517.5, 522.5, 545, 520,         535, 515, 540, 565, 550) denton_raw(x2, Y, freqratio = 5, conversion = \"Last\") #>  [1] 466.3462 471.1538 473.5577 478.3654 500.0000 476.4849 481.8265 484.7669 #>  [9] 487.7125 510.0000 497.5519 504.4298 499.2382 503.6937 525.0000 496.4508 #> [17] 506.1759 482.8297 501.6296 520.0000 506.1947 denton_raw(x2, Y, freqratio = 5, conversion = \"Last\", startoffset = 1) #>  [1] 489.8990 494.9495 497.4747 502.5253 525.2525 500.0000 503.0695 503.5940 #>  [9] 504.0987 524.4686 510.0000 519.4466 516.4758 523.4853 548.1341 525.0000 #> [17] 533.2790 506.7348 524.4042 541.4320 520.0000"},{"path":"https://rjdverse.github.io/rjd3bench/reference/deprecated-rjd3bench.html","id":null,"dir":"Reference","previous_headings":"","what":"Deprecated functions — deprecated-rjd3bench","title":"Deprecated functions — deprecated-rjd3bench","text":"function deprecated. start using functions temporal_disaggregation() temporal_interpolation() instead.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/deprecated-rjd3bench.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Deprecated functions — deprecated-rjd3bench","text":"","code":"temporaldisaggregation(   series,   constant = TRUE,   trend = FALSE,   indicators = NULL,   model = c(\"Ar1\", \"Rw\", \"RwAr1\"),   freq = 4L,   conversion = c(\"Sum\", \"Average\", \"Last\", \"First\", \"UserDefined\"),   conversion.obsposition = 1L,   rho = 0,   rho.fixed = FALSE,   rho.truncated = 0,   zeroinitialization = FALSE,   diffuse.algorithm = c(\"SqrtDiffuse\", \"Diffuse\", \"Augmented\"),   diffuse.regressors = FALSE )"},{"path":"https://rjdverse.github.io/rjd3bench/reference/deprecated-rjd3bench.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Deprecated functions — deprecated-rjd3bench","text":"series, constant, trend, indicators, model, freq, conversion, conversion.obsposition, rho, rho.fixed, rho.truncated, zeroinitialization, diffuse.algorithm, diffuse.regressors Parameters.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/grp.html","id":null,"dir":"Reference","previous_headings":"","what":"Benchmarking following the growth rate preservation principle. — grp","title":"Benchmarking following the growth rate preservation principle. — grp","text":"GRP method explicitly preserves period--period growth rates preliminary series. corresponds method Cauley Trager (1981), using solution proposed Di Fonzo Marini (2011). BFGS used line-search algorithm reduced unconstrained minimization problem.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/grp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Benchmarking following the growth rate preservation principle. — grp","text":"","code":"grp(   s,   t,   objective = c(\"Forward\", \"Backward\", \"Symmetric\", \"Log\"),   conversion = c(\"Sum\", \"Average\", \"Last\", \"First\", \"UserDefined\"),   obsposition = 1L,   eps = 1e-12,   iter = 500L,   dentoninitialization = TRUE )"},{"path":"https://rjdverse.github.io/rjd3bench/reference/grp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Benchmarking following the growth rate preservation principle. — grp","text":"s Preliminary series. Mandatory. must ts object. t Aggregation constraint. Mandatory. must ts object. objective Objective function. See vignette /Daalmans et al. (2018) information. conversion Conversion rule. \"Sum\" default. obsposition Position observation aggregated period (used \"UserDefined\" conversion) eps Numeric. Defines convergence precision. BFGS algorithm run reduction objective within eps value (1e-12 default) maximum number iterations hit. iter Integer. Maximum number iterations BFGS algorithm (500 default). dentoninitialization indicate whether series benchmarked via modified Denton PFD used starting values GRP optimization procedure (TRUE/FALSE, TRUE default). FALSE, average benchmark used flow variables (e.g. t/4 quarterly series annual constraints conversion = 'Sum'), benchmark stock variables.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/grp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Benchmarking following the growth rate preservation principle. — grp","text":"benchmarked series returned","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/grp.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Benchmarking following the growth rate preservation principle. — grp","text":"Causey, B., Trager, M.L. (1981). Derivation Solution   Benchmarking Problem: Trend Revision. Unpublished research notes, U.S.   Census Bureau, Washington D.C. Available appendix Bozik Otto   (1988). Di Fonzo, T., Marini, M. (2011). Newton's Method Benchmarking   Time Series according Growth Rates Preservation Principle. *IMF   WP/11/179*. Daalmans, J., Di Fonzo, T., Mushkudiani, N. Bikker, R. (2018). Growth   Rates Preservation (GRP) temporal benchmarking: Drawbacks alternative   solutions. *Statistics Canada*.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/grp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Benchmarking following the growth rate preservation principle. — grp","text":"","code":"data(\"qna_data\")  Y <- ts(qna_data$B1G_Y_data[, \"B1G_FF\"], frequency = 1, start = c(2009, 1)) x <- denton(t = Y, nfreq = 4) + rnorm(n = length(Y) * 4, mean = 0, sd = 10) grp(s = x, t = Y) #>          Qtr1     Qtr2     Qtr3     Qtr4 #> 2009 4391.190 4385.290 4401.376 4376.544 #> 2010 4370.800 4387.240 4437.022 4525.038 #> 2011 4632.272 4716.528 4763.753 4743.448 #> 2012 4736.253 4716.864 4696.824 4699.759 #> 2013 4667.696 4663.047 4674.790 4707.966 #> 2014 4722.907 4757.000 4762.253 4765.840 #> 2015 4787.509 4814.325 4829.647 4862.519 #> 2016 4905.966 4906.591 4938.273 4927.570 #> 2017 4957.467 4968.445 5062.909 5161.079 #> 2018 5280.554 5394.618 5502.633 5589.595 #> 2019 5635.901 5670.028 5638.706 5569.565 #> 2020 5471.618 5409.293 5365.378 5320.211"},{"path":"https://rjdverse.github.io/rjd3bench/reference/multivariatecholette.html","id":null,"dir":"Reference","previous_headings":"","what":"Reconciliation by means of the Multivariate Cholette method — multivariatecholette","title":"Reconciliation by means of the Multivariate Cholette method — multivariatecholette","text":"multivariate extension Cholette benchmarking method can used purpose reconciliation. standard benchmarking methods consider one target series time, reconciliation techniques aim restore consistency system time series regards contemporaneous temporal constraints. Reconciliation techniques typically needed total components estimated independently (-called direct approach). multivariate Cholette method relies principle movement preservation encompasses reconciliation methods multivariate Denton method.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/multivariatecholette.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reconciliation by means of the Multivariate Cholette method — multivariatecholette","text":"","code":"multivariatecholette(   xlist,   tcvector = NULL,   ccvector = NULL,   rho = 1,   lambda = 1 )"},{"path":"https://rjdverse.github.io/rjd3bench/reference/multivariatecholette.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reconciliation by means of the Multivariate Cholette method — multivariatecholette","text":"xlist named list ts objects including input. element list correspond one input series (preliminary series, low-frequency series corresponding one temporal aggregation constraints high-frequency series corresponding one contemporaneous constraints). tcvector character vector defining temporal constraints. element vector must written \"Y = sum(x)\" \"Y\" name low frequency temporal constraint \"x\" name high-frequency preliminary series. names one given 'xlist' argument. Default NULL, means temporal constraint considered. ccvector character vector defining contemporaneous constraints. element vector must written form \"z=[w1*]x1+...+[wn*]xn\" \"c=[w1*]x1+...+[wn*]xn\" \"z\" name high frequency contemporaneous constraint, wj optional numeric weights, \"x1,...,xn\" names high-frequency preliminary series c constant. \"+\" operator can replaced \"-\". names contemporaneous constraint(s) preliminary series one given 'xlist' argument. Note series put left hand side can’t appear right hand side constraint. left hand side quantities fixed right hand side quantities adjusted equality holds. Default NULL, means contemporaneous constraint considered. equivalent applying univariate Cholette method preliminary series separately. rho Numeric. Smoothing parameter whose value 0 1. See vignette information choice rho parameter. lambda Numeric. Adjustment model parameter. Typically, lambda = 0 additive benchmarking lambda close 1 approach proportional benchmarking. Unlike univariate case, setting lambda = 1 recommended option may result benchmarked series whose level differs strongly preliminary series. See vignette information choice lambda parameter.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/multivariatecholette.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reconciliation by means of the Multivariate Cholette method — multivariatecholette","text":"named list benchmarked series returned","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/multivariatecholette.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reconciliation by means of the Multivariate Cholette method — multivariatecholette","text":"","code":"# Example 1: one \"standard\" contemporaneous constraint: x1+x2+x3 = z  x1 <- ts(c(7, 7.2, 8.1, 7.5, 8.5, 7.8, 8.1, 8.4), frequency = 4, start = c(2010, 1)) x2 <- ts(c(18, 19.5, 19.0, 19.7, 18.5, 19.0, 20.3, 20.0), frequency = 4, start = c(2010, 1)) x3 <- ts(c(1.5, 1.8, 2, 2.5, 2.0, 1.5, 1.7, 2.0), frequency = 4, start = c(2010, 1))  z <- ts(c(27.1, 29.8, 29.9, 31.2, 29.3, 27.9, 30.9, 31.8), frequency = 4, start = c(2010, 1))  Y1 <- ts(c(30.0, 30.6), frequency = 1, start = c(2010, 1)) Y2 <- ts(c(80.0, 81.2), frequency = 1, start = c(2010, 1)) Y3 <- ts(c(8.0, 8.1), frequency = 1, start = c(2010, 1))  ### check consistency between temporal and contemporaneous constraints lfs <- cbind(Y1,Y2,Y3) rowSums(lfs) - stats::aggregate.ts(z) # should all be 0 #> Time Series: #> Start = 2010  #> End = 2011  #> Frequency = 1  #> [1] 0 0  data_list <- list(x1 = x1, x2 = x2, x3 = x3, z = z, Y1 = Y1, Y2 = Y2, Y3 = Y3) tc <- c(\"Y1 = sum(x1)\", \"Y2 = sum(x2)\", \"Y3 = sum(x3)\") # temporal constraints cc <- c(\"z = x1+x2+x3\") # contemporaneous constraints  multivariatecholette(xlist = data_list, tcvector = tc, ccvector = cc, rho = 1, lambda = .5) # Denton #> $x1 #>          Qtr1     Qtr2     Qtr3     Qtr4 #> 2010 7.045542 7.376876 8.064691 7.512891 #> 2011 8.023645 7.033308 7.564454 7.978594 #>  #> $x2 #>          Qtr1     Qtr2     Qtr3     Qtr4 #> 2010 18.58604 20.59697 19.79830 21.01869 #> 2011 19.12180 19.22024 21.37601 21.48195 #>  #> $x3 #>          Qtr1     Qtr2     Qtr3     Qtr4 #> 2010 1.468420 1.826157 2.037007 2.668416 #> 2011 2.154551 1.646451 1.959538 2.339460 #>  multivariatecholette(xlist = data_list, tcvector = tc, ccvector = cc, rho = 0.729, lambda = .5) # Cholette #> $x1 #>          Qtr1     Qtr2     Qtr3     Qtr4 #> 2010 7.070672 7.385807 8.059196 7.484325 #> 2011 7.945589 6.975158 7.571946 8.107307 #>  #> $x2 #>          Qtr1     Qtr2     Qtr3     Qtr4 #> 2010 18.55121 20.58910 19.81051 21.04918 #> 2011 19.17769 19.26249 21.36970 21.39013 #>  #> $x3 #>          Qtr1     Qtr2     Qtr3     Qtr4 #> 2010 1.478117 1.825096 2.030295 2.666492 #> 2011 2.176725 1.662357 1.958353 2.302565 #>  multivariatecholette(xlist = data_list, tcvector = NULL, ccvector = cc, rho = 1, lambda = .5) # no temporal constraints #> $x1 #>            Qtr1       Qtr2       Qtr3       Qtr4 #> 2010 0.09471188 0.24191380 0.61537179 0.19776270 #> 2011 0.75425553 0.33620487 0.74406548 0.97135123 #>  #> $x2 #>          Qtr1     Qtr2     Qtr3     Qtr4 #> 2010 19.70581 21.39462 20.60378 21.06272 #> 2011 19.88066 20.29720 22.26361 22.09731 #>  #> $x3 #>          Qtr1     Qtr2     Qtr3     Qtr4 #> 2010 7.299482 8.163465 8.680845 9.939513 #> 2011 8.665084 7.266593 7.892321 8.731341 #>   # Example 2: two contemporaneous constraints: x1+3*x2+0.5*x3+x4+x5 = z1 and x1+x2 = x4  x1 <- ts(c(7.0,7.3,8.1,7.5,8.5,7.8,8.1,8.4), frequency=4, start=c(2010,1)) x2 <- ts(c(1.5,1.8,2.0,2.5,2.0,1.5,1.7,2.0), frequency=4, start=c(2010,1)) x3 <- ts(c(18.0,19.5,19.0,19.7,18.5,19.0,20.3,20.0), frequency=4, start=c(2010,1)) x4 <- ts(c(8,9.5,9.0,10.7,8.5,10.0,10.3,9.0), frequency=4, start=c(2010,1)) x5 <- ts(c(5,9.6,7.2,7.1,4.3,4.6,5.3,5.9), frequency=4, start=c(2010,1))  z1 <- ts(c(38.1,41.8,41.9,43.2,38.8,39.1,41.9,43.7), frequency=4, start=c(2010,1))  Y1 <- ts(c(30.0,30.5), frequency=1, start=c(2010,1)) Y2 <- ts(c(10.0,10.5), frequency=1, start=c(2010,1)) Y3 <- ts(c(80.0,81.0), frequency=1, start=c(2010,1)) Y4 <- ts(c(40.0,41.0), frequency=1, start=c(2010,1)) Y5 <- ts(c(25.0,20.0), frequency=1, start=c(2010,1))  ### check consistency between temporal and contemporaneous constraints lfs <- cbind(Y1,3*Y2,0.5*Y3,Y4,Y5) rowSums(lfs) - stats::aggregate.ts(z1) # should all be 0 #> Time Series: #> Start = 2010  #> End = 2011  #> Frequency = 1  #> [1] 0 0  data.list <- list(x1=x1,x2=x2,x3=x3,x4=x4,x5=x5,z1=z1,Y1=Y1,Y2=Y2,Y3=Y3,Y4=Y4,Y5=Y5) tc <- c(\"Y1=sum(x1)\", \"Y2=sum(x2)\", \"Y3=sum(x3)\", \"Y4=sum(x4)\", \"Y5=sum(x5)\") cc <- c(\"z1=x1+3*x2+0.5*x3+x4+x5\", \"0=x1+x2-x4\")  multivariatecholette(data.list, tc, cc, rho=1, lambda=.5) #> $x1 #>          Qtr1     Qtr2     Qtr3     Qtr4 #> 2010 7.461426 7.453406 7.724638 7.360531 #> 2011 7.347524 7.756222 7.876066 7.520188 #>  #> $x2 #>          Qtr1     Qtr2     Qtr3     Qtr4 #> 2010 2.230614 2.193747 2.520035 3.055604 #> 2011 2.602163 2.310811 2.591295 2.995731 #>  #> $x3 #>          Qtr1     Qtr2     Qtr3     Qtr4 #> 2010 19.66444 20.17525 19.99352 20.16679 #> 2011 19.33101 19.71956 20.96161 20.98781 #>  #> $x4 #>           Qtr1      Qtr2      Qtr3      Qtr4 #> 2010  9.692039  9.647153 10.244673 10.416135 #> 2011  9.949687 10.067033 10.467361 10.515919 #>  #> $x5 #>          Qtr1     Qtr2     Qtr3     Qtr4 #> 2010 4.422475 8.030573 6.373824 6.173128 #> 2011 4.030796 4.484531 5.301882 6.182792 #>"},{"path":"https://rjdverse.github.io/rjd3bench/reference/plot.JD3AdlDisagg.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot function for object of class JD3AdlDisagg — plot.JD3AdlDisagg","title":"Plot function for object of class JD3AdlDisagg — plot.JD3AdlDisagg","text":"Plot function object class JD3AdlDisagg","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/plot.JD3AdlDisagg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot function for object of class JD3AdlDisagg — plot.JD3AdlDisagg","text":"","code":"# S3 method for class 'JD3AdlDisagg' plot(x, ...)"},{"path":"https://rjdverse.github.io/rjd3bench/reference/plot.JD3AdlDisagg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot function for object of class JD3AdlDisagg — plot.JD3AdlDisagg","text":"x object class JD3AdlDisagg ... arguments pass ts.plot.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/plot.JD3AdlDisagg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot function for object of class JD3AdlDisagg — plot.JD3AdlDisagg","text":"","code":"Y <- rjd3toolkit::aggregate(rjd3toolkit::Retail$RetailSalesTotal, 1) x <- rjd3toolkit::Retail$FoodAndBeverageStores td <- adl_disaggregation(Y, indicators = x, xar = \"FREE\") #> Warning: NaNs produced plot(td)"},{"path":"https://rjdverse.github.io/rjd3bench/reference/plot.JD3Interpolation.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot function for object of class JD3Interpolation — plot.JD3Interpolation","title":"Plot function for object of class JD3Interpolation — plot.JD3Interpolation","text":"Plot function object class JD3Interpolation","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/plot.JD3Interpolation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot function for object of class JD3Interpolation — plot.JD3Interpolation","text":"","code":"# S3 method for class 'JD3Interpolation' plot(x, ...)"},{"path":"https://rjdverse.github.io/rjd3bench/reference/plot.JD3Interpolation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot function for object of class JD3Interpolation — plot.JD3Interpolation","text":"x object class JD3Interpolation ... arguments pass ts.plot.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/plot.JD3Interpolation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot function for object of class JD3Interpolation — plot.JD3Interpolation","text":"","code":"Y <- rjd3toolkit::aggregate(rjd3toolkit::Retail$RetailSalesTotal, 1) x <- rjd3toolkit::Retail$FoodAndBeverageStores ti <- temporal_interpolation(Y, indicators = x) plot(ti)"},{"path":"https://rjdverse.github.io/rjd3bench/reference/plot.JD3MBDenton.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot function for object of class JD3MBDenton — plot.JD3MBDenton","title":"Plot function for object of class JD3MBDenton — plot.JD3MBDenton","text":"Plot function object class JD3MBDenton","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/plot.JD3MBDenton.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot function for object of class JD3MBDenton — plot.JD3MBDenton","text":"","code":"# S3 method for class 'JD3MBDenton' plot(x, ...)"},{"path":"https://rjdverse.github.io/rjd3bench/reference/plot.JD3MBDenton.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot function for object of class JD3MBDenton — plot.JD3MBDenton","text":"x object class JD3MBDenton ... arguments pass ts.plot.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/plot.JD3MBDenton.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot function for object of class JD3MBDenton — plot.JD3MBDenton","text":"","code":"Y <- rjd3toolkit::aggregate(rjd3toolkit::Retail$RetailSalesTotal, 1) x <- rjd3toolkit::Retail$FoodAndBeverageStores td <- temporaldisaggregationI(Y, indicator = x) plot(td)"},{"path":"https://rjdverse.github.io/rjd3bench/reference/plot.JD3TempDisagg.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot function for object of class JD3TempDisagg — plot.JD3TempDisagg","title":"Plot function for object of class JD3TempDisagg — plot.JD3TempDisagg","text":"Plot function object class JD3TempDisagg","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/plot.JD3TempDisagg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot function for object of class JD3TempDisagg — plot.JD3TempDisagg","text":"","code":"# S3 method for class 'JD3TempDisagg' plot(x, ...)"},{"path":"https://rjdverse.github.io/rjd3bench/reference/plot.JD3TempDisagg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot function for object of class JD3TempDisagg — plot.JD3TempDisagg","text":"x object class JD3TempDisagg ... arguments pass ts.plot.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/plot.JD3TempDisagg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot function for object of class JD3TempDisagg — plot.JD3TempDisagg","text":"","code":"Y <- rjd3toolkit::aggregate(rjd3toolkit::Retail$RetailSalesTotal, 1) x <- rjd3toolkit::Retail$FoodAndBeverageStores td <- temporal_disaggregation(Y, indicators = x) plot(td)"},{"path":"https://rjdverse.github.io/rjd3bench/reference/plot.JD3TempDisaggI.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot function for object of class JD3TempDisaggI — plot.JD3TempDisaggI","title":"Plot function for object of class JD3TempDisaggI — plot.JD3TempDisaggI","text":"Plot function object class JD3TempDisaggI","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/plot.JD3TempDisaggI.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot function for object of class JD3TempDisaggI — plot.JD3TempDisaggI","text":"","code":"# S3 method for class 'JD3TempDisaggI' plot(x, ...)"},{"path":"https://rjdverse.github.io/rjd3bench/reference/plot.JD3TempDisaggI.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot function for object of class JD3TempDisaggI — plot.JD3TempDisaggI","text":"x object class JD3TempDisaggI ... arguments pass ts.plot.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/plot.JD3TempDisaggI.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot function for object of class JD3TempDisaggI — plot.JD3TempDisaggI","text":"","code":"Y <- rjd3toolkit::aggregate(rjd3toolkit::Retail$RetailSalesTotal, 1) x <- rjd3toolkit::Retail$FoodAndBeverageStores td <- temporaldisaggregationI(Y, indicator = x) plot(td)"},{"path":"https://rjdverse.github.io/rjd3bench/reference/print.JD3AdlDisagg.html","id":null,"dir":"Reference","previous_headings":"","what":"Print function for object of class JD3AdlDisagg — print.JD3AdlDisagg","title":"Print function for object of class JD3AdlDisagg — print.JD3AdlDisagg","text":"Print function object class JD3AdlDisagg","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/print.JD3AdlDisagg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print function for object of class JD3AdlDisagg — print.JD3AdlDisagg","text":"","code":"# S3 method for class 'JD3AdlDisagg' print(x, ...)"},{"path":"https://rjdverse.github.io/rjd3bench/reference/print.JD3AdlDisagg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print function for object of class JD3AdlDisagg — print.JD3AdlDisagg","text":"x object class JD3AdlDisagg ... arguments passed methods.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/print.JD3AdlDisagg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print function for object of class JD3AdlDisagg — print.JD3AdlDisagg","text":"","code":"Y <- rjd3toolkit::aggregate(rjd3toolkit::Retail$RetailSalesTotal, 1) x <- rjd3toolkit::Retail$FoodAndBeverageStores td <- adl_disaggregation(Y, indicators = x, xar = \"FREE\") #> Warning: NaNs produced print(td) #> Model: FREE  #>          coef       se         t #> 1 -1542.99264 1208.321 -1.276972 #> 2    15.74617      NaN       NaN #> 3   -15.59888      NaN       NaN #>  #> Use summary() for more details.  #> Use plot() to see the decomposition of the disaggregated series."},{"path":"https://rjdverse.github.io/rjd3bench/reference/print.JD3Interpolation.html","id":null,"dir":"Reference","previous_headings":"","what":"Print function for object of class JD3Interpolation — print.JD3Interpolation","title":"Print function for object of class JD3Interpolation — print.JD3Interpolation","text":"Print function object class JD3Interpolation","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/print.JD3Interpolation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print function for object of class JD3Interpolation — print.JD3Interpolation","text":"","code":"# S3 method for class 'JD3Interpolation' print(x, ...)"},{"path":"https://rjdverse.github.io/rjd3bench/reference/print.JD3Interpolation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print function for object of class JD3Interpolation — print.JD3Interpolation","text":"x object class JD3Interpolation ... arguments passed methods.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/print.JD3Interpolation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print function for object of class JD3Interpolation — print.JD3Interpolation","text":"","code":"Y <- rjd3toolkit::aggregate(rjd3toolkit::Retail$RetailSalesTotal, 1) x <- rjd3toolkit::Retail$FoodAndBeverageStores ti <- temporal_interpolation(Y, indicators = x) print(ti) #> Model: Ar1  #>                coef           se         t #> const -1767664.6734 309535.20306 -5.710706 #> var-1      110.8141      7.09604 15.616330 #>  #> Use summary() for more details.  #> Use plot() to see the decomposition of the interpolated series."},{"path":"https://rjdverse.github.io/rjd3bench/reference/print.JD3InterpolationRaw.html","id":null,"dir":"Reference","previous_headings":"","what":"Print function for object of class JD3InterpolationRaw — print.JD3InterpolationRaw","title":"Print function for object of class JD3InterpolationRaw — print.JD3InterpolationRaw","text":"Print function object class JD3InterpolationRaw","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/print.JD3InterpolationRaw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print function for object of class JD3InterpolationRaw — print.JD3InterpolationRaw","text":"","code":"# S3 method for class 'JD3InterpolationRaw' print(x, ...)"},{"path":"https://rjdverse.github.io/rjd3bench/reference/print.JD3InterpolationRaw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print function for object of class JD3InterpolationRaw — print.JD3InterpolationRaw","text":"x object class JD3InterpolationRaw ... arguments passed methods.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/print.JD3InterpolationRaw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print function for object of class JD3InterpolationRaw — print.JD3InterpolationRaw","text":"","code":"Y <- stats::aggregate(rjd3toolkit::Retail$RetailSalesTotal, 0.5) x <- stats::aggregate(rjd3toolkit::Retail$FoodAndBeverageStores, 1) ti <- temporal_interpolation_raw(as.numeric(Y), indicators = as.numeric(x), freqratio = 2) print(ti) #> Model: Ar1  #>               coef           se         t #> C    -3.495942e+06 1.186404e+06 -2.946670 #> var1  2.082979e+01 2.594346e+00  8.028918"},{"path":"https://rjdverse.github.io/rjd3bench/reference/print.JD3MBDenton.html","id":null,"dir":"Reference","previous_headings":"","what":"Print function for object of class JD3MBDenton — print.JD3MBDenton","title":"Print function for object of class JD3MBDenton — print.JD3MBDenton","text":"Print function object class JD3MBDenton","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/print.JD3MBDenton.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print function for object of class JD3MBDenton — print.JD3MBDenton","text":"","code":"# S3 method for class 'JD3MBDenton' print(x, ...)"},{"path":"https://rjdverse.github.io/rjd3bench/reference/print.JD3MBDenton.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print function for object of class JD3MBDenton — print.JD3MBDenton","text":"x object class JD3MBDenton ... arguments passed methods.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/print.JD3MBDenton.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print function for object of class JD3MBDenton — print.JD3MBDenton","text":"","code":"Y <- rjd3toolkit::aggregate(rjd3toolkit::Retail$RetailSalesTotal, 1) x <- rjd3toolkit::aggregate(rjd3toolkit::Retail$FoodAndBeverageStores, 4) td <- denton_modelbased(Y, x, outliers = list(\"2000-01-01\" = 100, \"2005-07-01\" = 100)) print(td) #> Available estimates: #> [1] \"disagg\"   \"edisagg\"  \"biratio\"  \"ebiratio\" #>  #> Use summary() for more details.  #>  Use plot() to see the disaggregated series and BI ratio together  with their respective confidence interval"},{"path":"https://rjdverse.github.io/rjd3bench/reference/print.JD3TempDisagg.html","id":null,"dir":"Reference","previous_headings":"","what":"Print function for object of class JD3TempDisagg — print.JD3TempDisagg","title":"Print function for object of class JD3TempDisagg — print.JD3TempDisagg","text":"Print function object class JD3TempDisagg","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/print.JD3TempDisagg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print function for object of class JD3TempDisagg — print.JD3TempDisagg","text":"","code":"# S3 method for class 'JD3TempDisagg' print(x, ...)"},{"path":"https://rjdverse.github.io/rjd3bench/reference/print.JD3TempDisagg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print function for object of class JD3TempDisagg — print.JD3TempDisagg","text":"x object class JD3TempDisagg ... arguments passed methods.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/print.JD3TempDisagg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print function for object of class JD3TempDisagg — print.JD3TempDisagg","text":"","code":"Y <- rjd3toolkit::aggregate(rjd3toolkit::Retail$RetailSalesTotal, 1) x <- rjd3toolkit::Retail$FoodAndBeverageStores td <- temporaldisaggregation(Y, indicators = x) #> Warning: temporaldisaggregation() is deprecated. Use temporal_disaggregation() or temporal_interpolation() instead. print(td) #> Model: Ar1  #>                coef           se         t #> const -1.381801e+05 53219.499871 -2.596418 #> var-1  9.878469e+00     1.332681  7.412476 #>  #> Use summary() for more details.  #> Use plot() to see the decomposition of the disaggregated series."},{"path":"https://rjdverse.github.io/rjd3bench/reference/print.JD3TempDisaggI.html","id":null,"dir":"Reference","previous_headings":"","what":"Print function for object of class JD3TempDisaggI — print.JD3TempDisaggI","title":"Print function for object of class JD3TempDisaggI — print.JD3TempDisaggI","text":"Print function object class JD3TempDisaggI","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/print.JD3TempDisaggI.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print function for object of class JD3TempDisaggI — print.JD3TempDisaggI","text":"","code":"# S3 method for class 'JD3TempDisaggI' print(x, ...)"},{"path":"https://rjdverse.github.io/rjd3bench/reference/print.JD3TempDisaggI.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print function for object of class JD3TempDisaggI — print.JD3TempDisaggI","text":"x object class JD3TempDisaggI ... arguments passed methods.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/print.JD3TempDisaggI.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print function for object of class JD3TempDisaggI — print.JD3TempDisaggI","text":"","code":"Y <- rjd3toolkit::aggregate(rjd3toolkit::Retail$RetailSalesTotal, 1) x <- rjd3toolkit::Retail$FoodAndBeverageStores td <- temporaldisaggregationI(Y, indicator = x) print(td) #>         coef #> a 26898.3587 #> b     0.0542 #>  #> Use summary() for more details.  #> Use plot() to visualize the disaggregated series."},{"path":"https://rjdverse.github.io/rjd3bench/reference/print.JD3TempDisaggRaw.html","id":null,"dir":"Reference","previous_headings":"","what":"Print function for object of class JD3TempDisaggRaw — print.JD3TempDisaggRaw","title":"Print function for object of class JD3TempDisaggRaw — print.JD3TempDisaggRaw","text":"Print function object class JD3TempDisaggRaw","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/print.JD3TempDisaggRaw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print function for object of class JD3TempDisaggRaw — print.JD3TempDisaggRaw","text":"","code":"# S3 method for class 'JD3TempDisaggRaw' print(x, ...)"},{"path":"https://rjdverse.github.io/rjd3bench/reference/print.JD3TempDisaggRaw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print function for object of class JD3TempDisaggRaw — print.JD3TempDisaggRaw","text":"x object class JD3TempDisaggRaw ... arguments passed methods.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/print.JD3TempDisaggRaw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print function for object of class JD3TempDisaggRaw — print.JD3TempDisaggRaw","text":"","code":"Y <- stats::aggregate(rjd3toolkit::Retail$RetailSalesTotal, 0.5) x <- stats::aggregate(rjd3toolkit::Retail$FoodAndBeverageStores, 1) td <- temporal_disaggregation_raw(as.numeric(Y), indicators = as.numeric(x), freqratio = 2) print(td) #> Model: Ar1  #>               coef           se         t #> C    -1.600099e+06 6.973803e+05 -2.294442 #> var1  9.863888e+00 1.493886e+00  6.602840"},{"path":"https://rjdverse.github.io/rjd3bench/reference/summary.JD3AdlDisagg.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary function for object of class JD3AdlDisagg — summary.JD3AdlDisagg","title":"Summary function for object of class JD3AdlDisagg — summary.JD3AdlDisagg","text":"Summary function object class JD3AdlDisagg","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/summary.JD3AdlDisagg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary function for object of class JD3AdlDisagg — summary.JD3AdlDisagg","text":"","code":"# S3 method for class 'JD3AdlDisagg' summary(object, ...)"},{"path":"https://rjdverse.github.io/rjd3bench/reference/summary.JD3AdlDisagg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary function for object of class JD3AdlDisagg — summary.JD3AdlDisagg","text":"object object class JD3AdlDisagg ... arguments passed methods.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/summary.JD3AdlDisagg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary function for object of class JD3AdlDisagg — summary.JD3AdlDisagg","text":"","code":"Y <- rjd3toolkit::aggregate(rjd3toolkit::Retail$RetailSalesTotal, 1) x <- rjd3toolkit::Retail$FoodAndBeverageStores td <- adl_disaggregation(Y, indicators = x) #> Warning: NaNs produced summary(td) #>  #> Likelihood statistics  #>  #> Number of observations:  19  #> Number of effective observations:  -1  #> Number of estimated parameters:  2  #> LogLikelihood:  -211.6667  #> Standard error:   #> AIC:  427.3333  #> BIC:  428.8785  #>  #>  #> Model: FREE  #> Rho : 0.98097  ( 0.01414316 ) #>  #>  #> Regression model  #>          coef       se         t #> 1 -1542.99264 1208.321 -1.276972 #> 2    15.74617      NaN       NaN #> 3   -15.59888      NaN       NaN"},{"path":"https://rjdverse.github.io/rjd3bench/reference/summary.JD3Interpolation.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary function for object of class JD3Interpolation — summary.JD3Interpolation","title":"Summary function for object of class JD3Interpolation — summary.JD3Interpolation","text":"Summary function object class JD3Interpolation","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/summary.JD3Interpolation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary function for object of class JD3Interpolation — summary.JD3Interpolation","text":"","code":"# S3 method for class 'JD3Interpolation' summary(object, ...)"},{"path":"https://rjdverse.github.io/rjd3bench/reference/summary.JD3Interpolation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary function for object of class JD3Interpolation — summary.JD3Interpolation","text":"object object class JD3Interpolation ... arguments passed methods.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/summary.JD3Interpolation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary function for object of class JD3Interpolation — summary.JD3Interpolation","text":"","code":"Y <- rjd3toolkit::aggregate(rjd3toolkit::Retail$RetailSalesTotal, 1) x <- rjd3toolkit::Retail$FoodAndBeverageStores ti <- temporal_interpolation(Y, indicators = x) summary(ti) #>  #> Likelihood statistics  #>  #> Number of observations:  19  #> Number of effective observations:  -1  #> Number of estimated parameters:  3  #> LogLikelihood:  -256.3886  #> Standard error:   #> AIC:  518.7773  #> BIC:  521.6106  #>  #>  #> Model: Ar1  #> Rho : 0  ( Inf ) #>  #>  #> Regression model  #>                coef           se         t #> const -1767664.6734 309535.20306 -5.710706 #> var-1      110.8141      7.09604 15.616330"},{"path":"https://rjdverse.github.io/rjd3bench/reference/summary.JD3InterpolationRaw.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary function for object of class JD3InterpolationRaw — summary.JD3InterpolationRaw","title":"Summary function for object of class JD3InterpolationRaw — summary.JD3InterpolationRaw","text":"Summary function object class JD3InterpolationRaw","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/summary.JD3InterpolationRaw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary function for object of class JD3InterpolationRaw — summary.JD3InterpolationRaw","text":"","code":"# S3 method for class 'JD3InterpolationRaw' summary(object, ...)"},{"path":"https://rjdverse.github.io/rjd3bench/reference/summary.JD3InterpolationRaw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary function for object of class JD3InterpolationRaw — summary.JD3InterpolationRaw","text":"object object class JD3InterpolationRaw ... arguments passed methods.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/summary.JD3InterpolationRaw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary function for object of class JD3InterpolationRaw — summary.JD3InterpolationRaw","text":"","code":"Y <- stats::aggregate(rjd3toolkit::Retail$RetailSalesTotal, 0.5) x <- stats::aggregate(rjd3toolkit::Retail$FoodAndBeverageStores, 1) ti <- temporal_interpolation_raw(as.numeric(Y), indicators = as.numeric(x), freqratio = 2) summary(ti) #>  #> Likelihood statistics  #>  #> Number of observations:  9  #> Number of effective observations:  -1  #> Number of estimated parameters:  3  #> LogLikelihood:  -128.9191  #> Standard error:   #> AIC:  263.8382  #> BIC:  264.4299  #>  #>  #> Model: Ar1  #> Rho : 0  ( 148081.9 ) #>  #>  #> Regression model  #>               coef           se         t #> C    -3.495942e+06 1.186404e+06 -2.946670 #> var1  2.082979e+01 2.594346e+00  8.028918"},{"path":"https://rjdverse.github.io/rjd3bench/reference/summary.JD3MBDenton.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary function for object of class JD3MBDenton — summary.JD3MBDenton","title":"Summary function for object of class JD3MBDenton — summary.JD3MBDenton","text":"Summary function object class JD3MBDenton","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/summary.JD3MBDenton.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary function for object of class JD3MBDenton — summary.JD3MBDenton","text":"","code":"# S3 method for class 'JD3MBDenton' summary(object, ...)"},{"path":"https://rjdverse.github.io/rjd3bench/reference/summary.JD3MBDenton.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary function for object of class JD3MBDenton — summary.JD3MBDenton","text":"object object class JD3MBDenton ... arguments passed methods.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/summary.JD3MBDenton.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary function for object of class JD3MBDenton — summary.JD3MBDenton","text":"","code":"Y <- rjd3toolkit::aggregate(rjd3toolkit::Retail$RetailSalesTotal, 1) x <- rjd3toolkit::aggregate(rjd3toolkit::Retail$FoodAndBeverageStores, 4) td <- denton_modelbased(Y, x, outliers = list(\"2000-01-01\" = 100, \"2005-07-01\" = 100)) summary(td) #>  #> Likelihood statistics  #>  #> Number of observations:  19  #> Number of effective observations:  -1  #> Number of estimated parameters:  1  #> Standard error:   #> AIC:  476.7895  #> BIC:  477.6799  #>  #>  #> Available estimates: #> [1] \"disagg\"   \"edisagg\"  \"biratio\"  \"ebiratio\""},{"path":"https://rjdverse.github.io/rjd3bench/reference/summary.JD3TempDisagg.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary function for object of class JD3TempDisagg — summary.JD3TempDisagg","title":"Summary function for object of class JD3TempDisagg — summary.JD3TempDisagg","text":"Summary function object class JD3TempDisagg","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/summary.JD3TempDisagg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary function for object of class JD3TempDisagg — summary.JD3TempDisagg","text":"","code":"# S3 method for class 'JD3TempDisagg' summary(object, ...)"},{"path":"https://rjdverse.github.io/rjd3bench/reference/summary.JD3TempDisagg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary function for object of class JD3TempDisagg — summary.JD3TempDisagg","text":"object object class JD3TempDisagg ... arguments passed methods.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/summary.JD3TempDisagg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary function for object of class JD3TempDisagg — summary.JD3TempDisagg","text":"","code":"Y <- rjd3toolkit::aggregate(rjd3toolkit::Retail$RetailSalesTotal, 1) x <- rjd3toolkit::Retail$FoodAndBeverageStores td <- temporal_disaggregation(Y, indicators = x) summary(td) #>  #> Likelihood statistics  #>  #> Number of observations:  19  #> Number of effective observations:  -1  #> Number of estimated parameters:  3  #> LogLikelihood:  -246.6472  #> Standard error:   #> AIC:  499.2945  #> BIC:  502.1278  #>  #>  #> Model: Ar1  #> Rho : 0.9808416  ( 0.004485386 ) #>  #>  #> Regression model  #>                coef           se         t #> const -1.381801e+05 53219.499871 -2.596418 #> var-1  9.878469e+00     1.332681  7.412476"},{"path":"https://rjdverse.github.io/rjd3bench/reference/summary.JD3TempDisaggI.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary function for object of class JD3TempDisaggI — summary.JD3TempDisaggI","title":"Summary function for object of class JD3TempDisaggI — summary.JD3TempDisaggI","text":"Summary function object class JD3TempDisaggI","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/summary.JD3TempDisaggI.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary function for object of class JD3TempDisaggI — summary.JD3TempDisaggI","text":"","code":"# S3 method for class 'JD3TempDisaggI' summary(object, ...)"},{"path":"https://rjdverse.github.io/rjd3bench/reference/summary.JD3TempDisaggI.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary function for object of class JD3TempDisaggI — summary.JD3TempDisaggI","text":"object object class JD3TempDisaggI ... arguments passed methods.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/summary.JD3TempDisaggI.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary function for object of class JD3TempDisaggI — summary.JD3TempDisaggI","text":"","code":"Y <- rjd3toolkit::aggregate(rjd3toolkit::Retail$RetailSalesTotal, 1) x <- rjd3toolkit::Retail$FoodAndBeverageStores td <- temporaldisaggregationI(Y, indicator = x) summary(td) #>  #> Likelihood statistics  #>  #> Number of observations:  19  #> Number of effective observations:  -1  #> Number of estimated parameters:  4  #> LogLikelihood:  -189.6422  #> Standard error:   #> AIC:  387.2844  #> BIC:  390.8459  #>  #>  #> Model:  #>         coef #> a 26898.3587 #> b     0.0542"},{"path":"https://rjdverse.github.io/rjd3bench/reference/summary.JD3TempDisaggRaw.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary function for object of class JD3TempDisaggRaw — summary.JD3TempDisaggRaw","title":"Summary function for object of class JD3TempDisaggRaw — summary.JD3TempDisaggRaw","text":"Summary function object class JD3TempDisaggRaw","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/summary.JD3TempDisaggRaw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary function for object of class JD3TempDisaggRaw — summary.JD3TempDisaggRaw","text":"","code":"# S3 method for class 'JD3TempDisaggRaw' summary(object, ...)"},{"path":"https://rjdverse.github.io/rjd3bench/reference/summary.JD3TempDisaggRaw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary function for object of class JD3TempDisaggRaw — summary.JD3TempDisaggRaw","text":"object object class JD3TempDisaggRaw ... arguments passed methods.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/summary.JD3TempDisaggRaw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary function for object of class JD3TempDisaggRaw — summary.JD3TempDisaggRaw","text":"","code":"Y <- stats::aggregate(rjd3toolkit::Retail$RetailSalesTotal, 0.5) x <- stats::aggregate(rjd3toolkit::Retail$FoodAndBeverageStores, 1) td <- temporal_disaggregation_raw(as.numeric(Y), indicators = as.numeric(x), freqratio = 2) summary(td) #>  #> Likelihood statistics  #>  #> Number of observations:  9  #> Number of effective observations:  -1  #> Number of estimated parameters:  3  #> LogLikelihood:  -126.87  #> Standard error:   #> AIC:  259.7401  #> BIC:  260.3317  #>  #>  #> Model: Ar1  #> Rho : 0.6210095  ( 0.1633212 ) #>  #>  #> Regression model  #>               coef           se         t #> C    -1.600099e+06 6.973803e+05 -2.294442 #> var1  9.863888e+00 1.493886e+00  6.602840"},{"path":"https://rjdverse.github.io/rjd3bench/reference/temporal_disaggregation.html","id":null,"dir":"Reference","previous_headings":"","what":"Temporal disaggregation of a time series by regression models. — temporal_disaggregation","title":"Temporal disaggregation of a time series by regression models. — temporal_disaggregation","text":"Perform temporal disaggregation low frequency high frequency time series regression models. Models included Chow-Lin, Fernandez, Litterman variants algorithms.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/temporal_disaggregation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Temporal disaggregation of a time series by regression models. — temporal_disaggregation","text":"","code":"temporal_disaggregation(   series,   constant = TRUE,   trend = FALSE,   indicators = NULL,   model = c(\"Ar1\", \"Rw\", \"RwAr1\"),   freq = 4L,   average = FALSE,   rho = 0,   rho.fixed = FALSE,   rho.truncated = 0,   zeroinitialization = FALSE,   diffuse.algorithm = c(\"SqrtDiffuse\", \"Diffuse\", \"Augmented\"),   diffuse.regressors = FALSE,   nbcsts = 0L,   nfcsts = 0L )"},{"path":"https://rjdverse.github.io/rjd3bench/reference/temporal_disaggregation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Temporal disaggregation of a time series by regression models. — temporal_disaggregation","text":"series low frequency time series disaggregated. must ts object. constant Constant term (T/F). used \"Ar1\" model zeroinitialization = F. trend Linear trend (T/F, F default) indicators High-frequency indicator(s) used temporal disaggregation. must (list ) ts object(s). model Model error term (disaggregated level). \"Ar1\" = Chow-Lin, \"Rw\" = Fernandez, \"RwAr1\" = Litterman. freq Integer. Annual frequency disaggregated series. Ignored indicator provided. average Average conversion (T/F). Default F, means additive conversion. rho (Initial) value parameter. used Ar1/RwAr1 models. rho.fixed Fixed rho (T/F, F default) rho.truncated Range rho evaluation ([rho.truncated, 1[) zeroinitialization initial values auto-regressive model fixed 0 (T/F, F default) diffuse.algorithm Algorithm used diffuse initialization. \"SqrtDiffuse\" default. diffuse.regressors Indicates coefficients regression model diffuse (T) fixed unknown (F, default) nbcsts Number backcast periods. Ignored indicator provided. nfcsts Number forecast periods. Ignored indicator provided.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/temporal_disaggregation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Temporal disaggregation of a time series by regression models. — temporal_disaggregation","text":"object class \"JD3TempDisagg\"","code":""},{"path":[]},{"path":"https://rjdverse.github.io/rjd3bench/reference/temporal_disaggregation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Temporal disaggregation of a time series by regression models. — temporal_disaggregation","text":"","code":"# chow-lin with monthly indicator Y <- rjd3toolkit::aggregate(rjd3toolkit::Retail$RetailSalesTotal, 1) x <- rjd3toolkit::Retail$FoodAndBeverageStores td <- temporal_disaggregation(Y, indicators = x) td$estimation$disagg #>           Jan      Feb      Mar      Apr      May      Jun      Jul      Aug #> 1992 137916.2 127636.4 138517.7 143927.8 158328.5 149506.4 165994.4 157106.1 #> 1993 146290.9 128256.0 152066.7 156486.6 167812.5 163176.0 180412.0 163065.1 #> 1994 155985.0 139247.5 173398.9 166717.7 177111.7 180704.9 188521.6 182227.7 #> 1995 168520.9 149989.8 182344.2 177053.4 191096.4 190264.4 195173.8 193101.2 #> 1996 179435.3 170227.9 193110.6 184407.0 206647.8 197638.4 207403.2 211601.9 #> 1997 195237.9 169237.7 207992.6 190264.2 219075.2 200135.7 218598.0 217058.6 #> 1998 202353.7 174820.8 202058.5 207469.2 225420.4 211913.4 232254.9 222452.2 #> 1999 212635.3 191944.3 225220.7 221938.2 241654.4 229761.2 252098.9 234332.2 #> 2000 220459.3 214640.6 244542.4 243574.2 256653.5 254895.8 261298.1 256676.4 #> 2001 234869.1 217233.2 253501.6 241471.0 267666.8 259748.6 261438.3 266512.4 #> 2002 248121.9 224394.8 267193.4 239316.0 276996.6 260785.1 271586.4 273492.2 #> 2003 261953.1 232128.8 263355.1 261124.9 286605.5 266429.9 287538.3 283834.3 #> 2004 279072.3 251916.1 276322.0 279278.5 300072.3 285913.0 306671.3 288229.1 #> 2005 289075.7 261988.0 305037.9 292996.1 313415.5 308576.3 321094.4 312769.7 #> 2006 297912.7 279466.4 315389.8 311076.6 334737.8 326677.8 334816.9 333352.5 #> 2007 318771.0 293740.0 334611.7 316630.6 349743.6 340016.0 341018.3 341834.3 #> 2008 325379.5 306804.6 334155.8 315345.2 355478.9 328328.9 346321.1 341955.0 #> 2009 307285.7 260043.2 288734.1 293851.8 320224.1 297357.7 315867.3 305260.0 #> 2010 302650.2 276723.8 316851.2 308077.3 335229.0 318399.9 338574.3 326435.3 #>           Sep      Oct      Nov      Dec #> 1992 144594.1 157550.7 148144.5 186493.2 #> 1993 157732.5 164226.6 160607.4 202115.8 #> 1994 175159.2 175396.9 176480.4 219069.5 #> 1995 182535.4 179420.3 186502.3 226501.9 #> 1996 185666.8 198697.8 203890.8 227937.5 #> 1997 196337.4 210469.8 208483.0 241112.8 #> 1998 209207.0 223073.5 214748.3 261333.0 #> 1999 231533.7 236719.8 234519.8 296197.4 #> 2000 245772.2 243067.1 251544.1 295632.2 #> 2001 248131.0 253908.4 261993.4 301251.1 #> 2002 245738.3 259914.1 270627.9 296155.3 #> 2003 261679.5 276245.4 276055.5 311203.6 #> 2004 285076.1 293043.8 292977.9 341857.6 #> 2005 304841.0 309399.8 312547.0 364949.5 #> 2006 316722.9 321745.1 330795.8 377441.7 #> 2007 321570.6 328295.3 339336.6 380229.9 #> 2008 309490.3 323626.9 320005.4 346041.4 #> 2009 289382.4 306533.4 302747.1 351184.0 #> 2010 318513.9 331406.2 334459.6 382144.2  # fernandez with/without quarterly indicator data(\"qna_data\") Y <- ts(qna_data$B1G_Y_data[,\"B1G_FF\"], frequency = 1, start = c(2009,1)) x <- ts(qna_data$TURN_Q_data[,\"TURN_INDEX_FF\"], frequency = 4, start = c(2009,1)) td1 <- temporal_disaggregation(Y, indicators = x, model = \"Rw\") td1$estimation$disagg #>          Qtr1     Qtr2     Qtr3     Qtr4 #> 2009 4054.319 4546.626 4230.812 4722.644 #> 2010 3965.439 4546.603 4200.157 5007.901 #> 2011 4142.939 4873.447 4470.202 5369.411 #> 2012 4364.657 4907.514 4519.913 5057.616 #> 2013 4338.360 4796.134 4474.717 5104.289 #> 2014 4485.847 4841.382 4510.477 5170.294 #> 2015 4415.320 4996.023 4612.936 5269.721 #> 2016 4513.425 5095.867 4714.789 5354.319 #> 2017 4692.663 5195.768 4717.649 5543.821 #> 2018 4925.526 5552.812 5207.136 6081.925 #> 2019 5249.821 5784.822 5326.067 6153.489 #> 2020 5228.107 5044.753 5176.463 6117.177 #> 2021 5355.338 6047.411 5450.219 6546.932  td2 <- temporal_disaggregation(Y, model = \"Rw\", nfcsts = 6) td2$estimation$disagg #>          Qtr1     Qtr2     Qtr3     Qtr4 #> 2009 4394.912 4392.387 4387.338 4379.763 #> 2010 4369.663 4389.768 4440.077 4520.592 #> 2011 4631.312 4708.675 4752.682 4763.331 #> 2012 4740.623 4720.261 4702.244 4686.572 #> 2013 4673.246 4669.967 4676.736 4693.552 #> 2014 4720.416 4743.795 4763.690 4780.100 #> 2015 4793.025 4810.385 4832.180 4858.410 #> 2016 4889.074 4913.550 4931.838 4943.938 #> 2017 4949.849 4987.264 5056.182 5156.604 #> 2018 5288.529 5402.627 5498.899 5577.345 #> 2019 5637.965 5658.447 5638.791 5578.997 #> 2020 5479.065 5404.116 5354.151 5329.168 #> 2021 5329.168 5329.168 5329.168 5329.168 #> 2022 5329.168 5329.168                    # chow-lin on index series Y_index <- 100 * Y / Y[1] x_index <- 100 * x / x[1] td3 <- temporal_disaggregation(Y, indicators = x, average = TRUE) td3$estimation$disagg #>          Qtr1     Qtr2     Qtr3     Qtr4 #> 2009 16328.55 18098.49 17036.42 18754.14 #> 2010 16074.89 18100.48 16925.50 19779.53 #> 2011 16842.84 19414.67 18022.13 21144.36 #> 2012 17640.81 19526.21 18182.77 20049.00 #> 2013 17508.95 19107.93 18013.75 20223.37 #> 2014 18079.35 19318.66 18167.70 20466.30 #> 2015 17874.01 19895.30 18559.96 20846.74 #> 2016 18234.19 20279.41 18977.63 21222.38 #> 2017 18931.73 20688.01 19034.39 21945.48 #> 2018 19929.86 22152.34 20964.98 24022.42 #> 2019 21151.75 23057.83 21500.42 24346.80 #> 2020 20922.72 20273.19 20818.86 24251.23 #> 2021 21872.07 24423.57 22425.88 26281.08"},{"path":"https://rjdverse.github.io/rjd3bench/reference/temporal_disaggregation_raw.html","id":null,"dir":"Reference","previous_headings":"","what":"Temporal disaggregation of an atypical frequency series by regression models. — temporal_disaggregation_raw","title":"Temporal disaggregation of an atypical frequency series by regression models. — temporal_disaggregation_raw","text":"Perform temporal disaggregation low frequency high frequency time series regression models. Models included Chow-Lin, Fernandez, Litterman variants algorithms. \"raw\" function extends temporal_disaggregation() function way can deal frequency ratio.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/temporal_disaggregation_raw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Temporal disaggregation of an atypical frequency series by regression models. — temporal_disaggregation_raw","text":"","code":"temporal_disaggregation_raw(   series,   constant = TRUE,   trend = FALSE,   indicators = NULL,   startoffset = 0L,   model = c(\"Ar1\", \"Rw\", \"RwAr1\"),   freqratio,   average = FALSE,   rho = 0,   rho.fixed = FALSE,   rho.truncated = 0,   zeroinitialization = FALSE,   diffuse.algorithm = c(\"SqrtDiffuse\", \"Diffuse\", \"Augmented\"),   diffuse.regressors = FALSE,   nbcsts = 0L,   nfcsts = 0L )"},{"path":"https://rjdverse.github.io/rjd3bench/reference/temporal_disaggregation_raw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Temporal disaggregation of an atypical frequency series by regression models. — temporal_disaggregation_raw","text":"series low frequency series disaggregated. Must numeric vector. constant Constant term (T/F). used \"Ar1\" model zeroinitialization = F. trend Linear trend (T/F) indicators High-frequency indicator(s) used temporal disaggregation. NULL, must either numeric vector matrix. startoffset Number initial observations indicator(s) series prior start period covered low-frequency series. Must 0 positive integer. 0 default. Ignored indicator provided. model Model error term (disaggregated level). \"Ar1\" = Chow-Lin, \"Rw\" = Fernandez, \"RwAr1\" = Litterman. freqratio Frequency ratio disaggregated series low frequency series. Mandatory. Must positive integer. average Average conversion (T/F). Default F, means additive conversion. rho (Initial) value parameter. used Ar1/RwAr1 models. rho.fixed Fixed rho (T/F, F default) rho.truncated Range Rho evaluation ([rho.truncated, 1[) zeroinitialization initial values auto-regressive model fixed 0 (T/F, F default) diffuse.algorithm Algorithm used diffuse initialization. \"SqrtDiffuse\" default diffuse.regressors Indicates coefficients regression model diffuse (T) fixed unknown (F, default) nbcsts Number backcast periods. Ignored indicator provided. nfcsts Number forecast periods. Ignored indicator provided.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/temporal_disaggregation_raw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Temporal disaggregation of an atypical frequency series by regression models. — temporal_disaggregation_raw","text":"object class \"JD3TempDisaggRaw\"","code":""},{"path":[]},{"path":"https://rjdverse.github.io/rjd3bench/reference/temporal_disaggregation_raw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Temporal disaggregation of an atypical frequency series by regression models. — temporal_disaggregation_raw","text":"","code":"# use of chow-lin method to disaggregate a biennial series with an annual indicator Y <- stats::aggregate(rjd3toolkit::Retail$RetailSalesTotal, 0.5) x <- stats::aggregate(rjd3toolkit::Retail$FoodAndBeverageStores, 1) td <- temporal_disaggregation_raw(as.numeric(Y), indicators = as.numeric(x), freqratio = 2) td$estimation$disagg #>  [1] 1853647 1904317 2106162 2226363 2362164 2478504 2596417 2799244 2935728 #> [10] 3120753 3141809 3260667 3478646 3698475 3902189 3983745 3853107 3738297 #> [19] 3973628  # use of Fernandez method to disaggregate a series without indicator considering a frequency ratio of 5 (for example, it could be a quinquennial series to disaggregate on an annual basis) Y2 <- c(500,510,525,520) td2 <- temporal_disaggregation_raw(Y2, model = \"Rw\", freqratio = 5, nfcsts = 2) td2$estimation$disagg #>  [1]  99.70153  99.77615  99.92538 100.14923 100.44770 100.82078 101.30213 #>  [8] 101.89174 102.58961 103.39574 104.31014 104.93980 105.28473 105.34493 #> [15] 105.12039 104.61112 104.20371 103.89815 103.69444 103.59258 103.59258 #> [22] 103.59258  # same with an indicator, considering an offset in the latter Y2 <- c(500,510,525,520) x2 <- c(97,         98, 98.5, 99.5, 104, 99,         100, 100.5, 101, 105.5, 103,         104.5, 103.5, 104.5, 109, 104,         107, 103, 108, 113, 110) td3 <- temporal_disaggregation_raw(Y2, indicators = x2, startoffset = 1, model = \"Rw\", freqratio = 5) td3$estimation$disagg #>  [1]  98.77697  99.16257  99.39121  99.84848 101.69120  99.90653 100.47131 #>  [8] 100.94308 101.51462 103.72835 103.34265 104.59913 104.59495 105.06531 #> [15] 106.58860 104.15201 104.50357 102.31697 103.76183 105.36774 104.04989"},{"path":"https://rjdverse.github.io/rjd3bench/reference/temporal_interpolation.html","id":null,"dir":"Reference","previous_headings":"","what":"Interpolation of a time series by regression models. — temporal_interpolation","title":"Interpolation of a time series by regression models. — temporal_interpolation","text":"Perform temporal interpolation low frequency high frequency time series regression models. Models included Chow-Lin, Fernandez, Litterman variants algorithms.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/temporal_interpolation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Interpolation of a time series by regression models. — temporal_interpolation","text":"","code":"temporal_interpolation(   series,   constant = TRUE,   trend = FALSE,   indicators = NULL,   model = c(\"Ar1\", \"Rw\", \"RwAr1\"),   freq = 4L,   obsposition = -1L,   rho = 0,   rho.fixed = FALSE,   rho.truncated = 0,   zeroinitialization = FALSE,   diffuse.algorithm = c(\"SqrtDiffuse\", \"Diffuse\", \"Augmented\"),   diffuse.regressors = FALSE,   nbcsts = 0L,   nfcsts = 0L )"},{"path":"https://rjdverse.github.io/rjd3bench/reference/temporal_interpolation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Interpolation of a time series by regression models. — temporal_interpolation","text":"series low frequency time series interpolated. must ts object. constant Constant term (T/F). used \"Ar1\" model zeroinitialization = F. trend Linear trend (T/F, F default) indicators High-frequency indicator(s) used interpolation. must (list ) ts object(s). model Model error term (higher-frequency level). \"Ar1\" = Chow-Lin, \"Rw\" = Fernandez, \"RwAr1\" = Litterman. freq Integer. Annual frequency interpolated series. Ignored indicator provided. obsposition Integer. Position observations low frequency series interpolated series. (e.g. 1st month year, 2d month year, etc.). must positive integer -1 (default). default value equivalent setting value parameter equal frequency series, meaning last value interpolated series consistent low frequency series. rho (Initial) value parameter. used Ar1/RwAr1 models. rho.fixed Fixed rho (T/F, F default) rho.truncated Range rho evaluation ([rho.truncated, 1[) zeroinitialization initial values auto-regressive model fixed 0 (T/F, F default) diffuse.algorithm Algorithm used diffuse initialization. \"SqrtDiffuse\" default. diffuse.regressors Indicates coefficients regression model diffuse (T) fixed unknown (F, default) nbcsts Number backcast periods. Ignored indicator provided. nfcsts Number forecast periods. Ignored indicator provided.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/temporal_interpolation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Interpolation of a time series by regression models. — temporal_interpolation","text":"object class \"JD3Interpolation\"","code":""},{"path":[]},{"path":"https://rjdverse.github.io/rjd3bench/reference/temporal_interpolation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Interpolation of a time series by regression models. — temporal_interpolation","text":"","code":"# chow-lin/fernandez when the last value of the interpolated series is # consistent with the low frequency series. Y <- rjd3toolkit::aggregate(rjd3toolkit::Retail$RetailSalesTotal, 1) x <- rjd3toolkit::Retail$FoodAndBeverageStores ti1 <- temporal_interpolation(Y, indicators = x) ti1$estimation$interp #>          Jan     Feb     Mar     Apr     May     Jun     Jul     Aug     Sep #> 1992 1519082 1406273 1529720 1590668 1751348 1650396 1832242 1728299 1582578 #> 1993 1568837 1357071 1615158 1656159 1775062 1715333 1901390 1699930 1633663 #> 1994 1592441 1399957 1778387 1698822 1810855 1846648 1929870 1854848 1771184 #> 1995 1679651 1467664 1826591 1763316 1917015 1903939 1955357 1928540 1806534 #> 1996 1758662 1652391 1906266 1805979 2052984 1949595 2056973 2102075 1809304 #> 1997 1910920 1617817 2050879 1850083 2171112 1956243 2160695 2140527 1904936 #> 1998 1957351 1644523 1946270 2003339 2201253 2046446 2271509 2158590 2007218 #> 1999 2036140 1801104 2170669 2129335 2345201 2205686 2449366 2242365 2202472 #> 2000 2036140 1961452 2289794 2274169 2418449 2398613 2472637 2425319 2309851 #> 2001 2238265 2054535 2473413 2348414 2650161 2567162 2589878 2648499 2441942 #> 2002 2419779 2145625 2618358 2298881 2715431 2528044 2644288 2661354 2346309 #> 2003 2519401 2183191 2531479 2504108 2787238 2557853 2791228 2745905 2493249 #> 2004 2668224 2358277 2627001 2655370 2884090 2720972 2949803 2739145 2700249 #> 2005 2733493 2427092 2907472 2769841 2996345 2939497 3077350 2981385 2889852 #> 2006 2801644 2592870 2994793 2946146 3212100 3123005 3216421 3202902 3020059 #> 2007 3065825 2793111 3260858 3069593 3452677 3356380 3381645 3406024 3195145 #> 2008 3315822 3129986 3460545 3274488 3750878 3473732 3704225 3685165 3352169 #> 2009 3465088 2966536 3314824 3393724 3706109 3461210 3675524 3558283 3376991 #> 2010 3463758 3151706 3582330 3466086 3754535 3551302 3764840 3617568 3519276 #>          Oct     Nov     Dec #> 1992 1721428 1608287 1815716 #> 1993 1700484 1654275 1942248 #> 1994 1769522 1777389 2110021 #> 1995 1768192 1844321 2222504 #> 1996 1953805 2010542 2366665 #> 1997 2060076 2034146 2474003 #> 1998 2160141 2064287 2587105 #> 1999 2251341 2216546 2808556 #> 2000 2288686 2395289 2988756 #> 2001 2504330 2590543 3067725 #> 2002 2502224 2619909 3134322 #> 2003 2652156 2645175 3268154 #> 2004 2786352 2782584 3480430 #> 2005 2938389 2971079 3696691 #> 2006 3080896 3187721 3880136 #> 2007 3288229 3430957 4005798 #> 2008 3543212 3536342 3952933 #> 2009 3561275 3505757 3638471 #> 2010 3656132 3684279 3889465  ti2 <- temporal_interpolation(Y, indicators = x, model = \"Rw\") ti2$estimation$interp #>          Jan     Feb     Mar     Apr     May     Jun     Jul     Aug     Sep #> 1992 1478427 1403913 1485454 1525712 1631847 1565165 1685280 1616622 1520369 #> 1993 1517158 1383146 1559486 1592435 1676840 1643253 1772016 1644811 1606905 #> 1994 1603758 1483101 1739551 1693480 1773966 1804093 1865548 1822479 1773700 #> 1995 1739927 1607135 1851450 1816888 1925643 1924239 1965435 1954954 1881597 #> 1996 1884285 1826701 2007005 1953374 2129139 2073458 2156997 2199399 2018625 #> 1997 2126065 1934946 2223483 2093336 2307871 2168429 2305961 2295125 2141995 #> 1998 2183134 1975563 2173938 2210696 2340486 2237293 2385016 2309491 2208567 #> 1999 2226085 2072064 2317403 2291329 2435144 2344219 2506406 2370904 2345782 #> 2000 2254276 2219617 2451173 2455527 2565504 2567077 2630647 2614067 2552472 #> 2001 2549150 2427729 2704349 2621722 2820974 2766088 2781031 2819690 2683191 #> 2002 2680522 2511590 2836001 2637131 2924432 2812813 2901752 2925180 2729238 #> 2003 2884042 2665968 2900028 2885952 3076973 2929460 3087615 3061682 2898798 #> 2004 3027900 2824683 3003697 3023949 3176539 3070308 3222971 3085338 3061160 #> 2005 3093121 2896196 3218964 3133517 3288593 3256505 3353024 3295099 3240101 #> 2006 3204660 3073195 3345114 3319418 3501525 3449112 3517253 3514759 3400422 #> 2007 3449826 3269554 3578380 3451908 3704812 3641069 3657622 3673590 3534161 #> 2008 3611610 3487004 3703493 3578740 3891556 3706636 3857029 3842583 3620772 #> 2009 3654358 3289614 3484236 3500918 3671824 3474626 3580754 3467878 3312695 #> 2010 3274515 3079203 3374453 3308479 3509818 3386385 3538243 3451774 3397658 #>          Oct     Nov     Dec #> 1992 1612084 1537350 1815716 #> 1993 1656908 1632251 1942248 #> 1994 1779087 1790769 2110021 #> 1995 1863504 1921022 2222504 #> 1996 2126685 2176772 2366665 #> 1997 2246955 2232312 2474003 #> 1998 2308639 2244386 2587105 #> 1999 2379291 2357536 2808556 #> 2000 2553166 2638256 2988756 #> 2001 2724338 2781223 3067725 #> 2002 2844381 2934271 3134322 #> 2003 3007765 3007158 3268154 #> 2004 3119547 3118571 3480430 #> 2005 3277623 3304679 3696691 #> 2006 3447043 3524041 3880136 #> 2007 3595511 3689652 4005798 #> 2008 3745107 3738713 3952933 #> 2009 3398987 3326881 3638471 #> 2010 3498864 3528265 3889465  # same without indicator ti3 <- temporal_interpolation(Y, model = \"Rw\", freq = 12, nfcsts = 6) ti3$estimation$interp #>          Jan     Feb     Mar     Apr     May     Jun     Jul     Aug     Sep #> 1992                                                                         #> 1993 1826260 1836805 1847349 1857893 1868438 1878982 1889526 1900071 1910615 #> 1994 1956229 1970210 1984191 1998172 2012153 2026135 2040116 2054097 2068078 #> 1995 2119395 2128768 2138142 2147515 2156889 2166262 2175636 2185010 2194383 #> 1996 2234517 2246531 2258544 2270558 2282571 2294584 2306598 2318611 2330625 #> 1997 2375610 2384555 2393500 2402444 2411389 2420334 2429279 2438224 2447168 #> 1998 2483428 2492853 2502279 2511704 2521129 2530554 2539979 2549404 2558830 #> 1999 2605559 2624014 2642468 2660922 2679376 2697831 2716285 2734739 2753193 #> 2000 2823573 2838589 2853606 2868623 2883639 2898656 2913673 2928689 2943706 #> 2001 2995337 3001918 3008498 3015079 3021660 3028240 3034821 3041402 3047983 #> 2002 3073275 3078825 3084374 3089924 3095474 3101024 3106573 3112123 3117673 #> 2003 3145475 3156627 3167780 3178933 3190085 3201238 3212391 3223543 3234696 #> 2004 3285844 3303533 3321223 3338913 3356602 3374292 3391982 3409671 3427361 #> 2005 3498452 3516474 3534495 3552517 3570539 3588561 3606582 3624604 3642626 #> 2006 3711978 3727265 3742552 3757839 3773126 3788414 3803701 3818988 3834275 #> 2007 3890608 3901080 3911552 3922023 3932495 3942967 3953439 3963911 3974382 #> 2008 4001393 3996987 3992582 3988176 3983771 3979366 3974960 3970555 3966149 #> 2009 3926728 3900523 3874318 3848112 3821907 3795702 3769497 3743292 3717086 #> 2010 3659387 3680303 3701220 3722136 3743052 3763968 3784884 3805800 3826717 #> 2011 3889465 3889465 3889465 3889465 3889465 3889465                         #>          Oct     Nov     Dec #> 1992                 1815716 #> 1993 1921159 1931704 1942248 #> 1994 2082059 2096040 2110021 #> 1995 2203757 2213130 2222504 #> 1996 2342638 2354652 2366665 #> 1997 2456113 2465058 2474003 #> 1998 2568255 2577680 2587105 #> 1999 2771648 2790102 2808556 #> 2000 2958723 2973739 2988756 #> 2001 3054564 3061144 3067725 #> 2002 3123222 3128772 3134322 #> 2003 3245849 3257001 3268154 #> 2004 3445051 3462740 3480430 #> 2005 3660648 3678669 3696691 #> 2006 3849562 3864849 3880136 #> 2007 3984854 3995326 4005798 #> 2008 3961744 3957338 3952933 #> 2009 3690881 3664676 3638471 #> 2010 3847633 3868549 3889465 #> 2011                          # consistent with the low frequency series. ti4 <- temporal_interpolation(Y, indicators = x, obsposition = 1) ti4$estimation$interp #>          Jan     Feb     Mar     Apr     May     Jun     Jul     Aug     Sep #> 1992 1815716 2018872 2148753 2212877 2381932 2275719 2467043 2357682 2204366 #> 1993 1942248 1967106 2238643 2281782 2406882 2344041 2539795 2327835 2258114 #> 1994 2110021 2012226 2410380 2326669 2444541 2482199 2569758 2490827 2402802 #> 1995 2222504 2083462 2461097 2394524 2556234 2542476 2596574 2568359 2439994 #> 1996 2366665 2277818 2544925 2439411 2699290 2590511 2703487 2750939 2442909 #> 1997 2474003 2241442 2697074 2485814 2823574 2597507 2812615 2791395 2543526 #> 1998 2587105 2269540 2587014 2647057 2855287 2692411 2929205 2810400 2651138 #> 1999 2808556 2434281 2823108 2779620 3006737 2859950 3116331 2898541 2856569 #> 2000 2988756 2602986 2948442 2932003 3083803 3062933 3140815 3091031 2969545 #> 2001 3067725 2700922 3141631 3010118 3327592 3240266 3264167 3325843 3108520 #> 2002 3134322 2796759 3294131 2958002 3396263 3199110 3321413 3339367 3007903 #> 2003 3268154 2836283 3202724 3173926 3471813 3230473 3476011 3428325 3162501 #> 2004 3480430 3020494 3303225 3333072 3573713 3402093 3642850 3421213 3380290 #> 2005 3696691 3092897 3598313 3453509 3691818 3632008 3777045 3676079 3579775 #> 2006 3880136 3267315 3690186 3639003 3918818 3825080 3923365 3909142 3716768 #> 2007 4005798 3477993 3970118 3768884 4171935 4070618 4097201 4122851 3900980 #> 2008 3952933 3832425 4180213 3984458 4485678 4194087 4436594 4416540 4066188 #> 2009 3638471 3660456 4026897 4109909 4438576 4180912 4406397 4283045 4092304 #> 2010 3889465 3855277 4308345 4186042 4489525 4275700 4500368 4345420 4242005 #>          Oct     Nov     Dec #> 1992 2350453 2231415 2674806 #> 1993 2328418 2279800 2764230 #> 1994 2401053 2409331 2907519 #> 1995 2399654 2479751 2948442 #> 1996 2594942 2654636 2937016 #> 1997 2706751 2679469 3060485 #> 1998 2812032 2711182 3258571 #> 1999 2907985 2871376 3587820 #> 2000 2947276 3059435 3594349 #> 2001 3174160 3264866 3721315 #> 2002 3171944 3295763 3595049 #> 2003 3329690 3322345 3731692 #> 2004 3470881 3466917 4040888 #> 2005 3630842 3665236 4280946 #> 2006 3780776 3893169 4450118 #> 2007 3998916 4149083 4652868 #> 2008 4267189 4259960 4604133 #> 2009 4286193 4227781 4780533 #> 2010 4385994 4415607 4973723"},{"path":"https://rjdverse.github.io/rjd3bench/reference/temporal_interpolation_raw.html","id":null,"dir":"Reference","previous_headings":"","what":"Interpolation of an atypical frequency series by regression models. — temporal_interpolation_raw","title":"Interpolation of an atypical frequency series by regression models. — temporal_interpolation_raw","text":"Perform temporal interpolation low frequency high frequency time series regression models. Models included Chow-Lin, Fernandez, Litterman variants algorithms. \"raw\" function extends temporal_interpolation() function way can deal frequency ratio.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/temporal_interpolation_raw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Interpolation of an atypical frequency series by regression models. — temporal_interpolation_raw","text":"","code":"temporal_interpolation_raw(   series,   constant = TRUE,   trend = FALSE,   indicators = NULL,   startoffset = 0L,   model = c(\"Ar1\", \"Rw\", \"RwAr1\"),   freqratio,   obsposition = -1L,   rho = 0,   rho.fixed = FALSE,   rho.truncated = 0,   zeroinitialization = FALSE,   diffuse.algorithm = c(\"SqrtDiffuse\", \"Diffuse\", \"Augmented\"),   diffuse.regressors = FALSE,   nbcsts = 0L,   nfcsts = 0L )"},{"path":"https://rjdverse.github.io/rjd3bench/reference/temporal_interpolation_raw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Interpolation of an atypical frequency series by regression models. — temporal_interpolation_raw","text":"series low frequency series interpolated. Must numeric vector. constant Constant term (T/F). used \"Ar1\" model zeroinitialization = F. trend Linear trend (T/F, F default) indicators High-frequency indicator(s) used interpolation. NULL, must either numeric vector matrix. startoffset Number initial observations indicator(s) series   prior first observation low-frequency series. Must 0 positive integer. 0 default. Ignored indicator provided. model Model error term (higher-frequency level). \"Ar1\" = Chow-Lin, \"Rw\" = Fernandez, \"RwAr1\" = Litterman. freqratio Frequency ratio interpolated series low frequency series. Mandatory. Must positive integer. obsposition Integer. Position observations low frequency series interpolated series. (e.g. 1st month year, 2d month year, etc.). must positive integer -1 (default). default value equivalent setting value parameter equal frequency series, meaning last value interpolated series consistent low frequency series. rho (Initial) value parameter. used Ar1/RwAr1 models. rho.fixed Fixed rho (T/F, F default) rho.truncated Range Rho evaluation ([rho.truncated, 1[) zeroinitialization initial values auto-regressive model fixed 0 (T/F, F default) diffuse.algorithm Algorithm used diffuse initialization. \"SqrtDiffuse\" default diffuse.regressors Indicates coefficients regression model diffuse (T) fixed unknown (F, default) nbcsts Number backcast periods. Ignored indicator provided. nfcsts Number forecast periods. Ignored indicator provided.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/temporal_interpolation_raw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Interpolation of an atypical frequency series by regression models. — temporal_interpolation_raw","text":"object class \"JD3InterpolationRaw\"","code":""},{"path":[]},{"path":"https://rjdverse.github.io/rjd3bench/reference/temporal_interpolation_raw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Interpolation of an atypical frequency series by regression models. — temporal_interpolation_raw","text":"","code":"# use of chow-lin method to interpolate a biennial series with an annual indicator # (low frequency series consistent with the last value of the interpolated series) Y <- stats::aggregate(rjd3toolkit::Retail$RetailSalesTotal, 0.5) x <- stats::aggregate(rjd3toolkit::Retail$FoodAndBeverageStores, 1) ti <- temporal_interpolation_raw(as.numeric(Y), indicators = as.numeric(x), freqratio = 2) ti$estimation$interp #>  [1] 3757964 4324395 4332525 4655006 4840668 5050272 5395661 5556665 6056481 #> [10] 6155126 6402476 6402063 7177121 7105610 7885934 7936844 7591404 8389142 #> [19] 8654201  # use of Fernandez method to interpolate a series without indicator considering a frequency ratio of 5 (for example, it could be a quinquennial series to interpolate annually) # (low frequency series consistent with the last value of the interpolated series) Y2 <- c(500,510,525,520) ti2 <- temporal_interpolation_raw(Y2, model = \"Rw\", freqratio = 5, nbcsts = 1, nfcsts = 2) ti2$estimation$interp #>  [1] 500 500 502 504 506 508 510 513 516 519 522 525 524 523 522 521 520 520 520  # same with an indicator, considering an offset in the latter Y2 <- c(500,510,525,520) x2 <- c(485,         490, 492.5, 497.5, 520, 495,         500, 502.5, 505, 527.5, 515,         522.5, 517.5, 522.5, 545, 520,         535, 515, 540, 565, 550) ti3 <- temporal_interpolation_raw(Y2, indicators = x2, startoffset = 1, model = \"Rw\", freqratio = 5) ti3$estimation$interp #>  [1] 497.5410 500.0000 502.2459 505.7213 517.8033 506.5246 510.0000 512.0164 #>  [9] 514.0328 525.8852 520.5246 525.0000 520.3115 520.5410 529.3770 514.8525 #> [17] 520.0000 510.1639 522.4590 534.7541 527.3770  # same considering that the first value of the interpolated series is the one consistent with the low frequency series ti4 <- temporal_interpolation_raw(Y2, indicators = x2, startoffset = 1, model = \"Rw\", freqratio = 5, obsposition = 1) ti4$estimation$interp #>  [1] 497.5410 500.0000 502.2459 505.7213 517.8033 506.5246 510.0000 512.0164 #>  [9] 514.0328 525.8852 520.5246 525.0000 520.3115 520.5410 529.3770 514.8525 #> [17] 520.0000 510.1639 522.4590 534.7541 527.3770"},{"path":"https://rjdverse.github.io/rjd3bench/reference/temporaldisaggregationI.html","id":null,"dir":"Reference","previous_headings":"","what":"Temporal disaggregation using the model: x(t) = a + b y(t), where x(t) is the indicator, y(t) is the unknown target series, with low-frequency constraints on y. — temporaldisaggregationI","title":"Temporal disaggregation using the model: x(t) = a + b y(t), where x(t) is the indicator, y(t) is the unknown target series, with low-frequency constraints on y. — temporaldisaggregationI","text":"Temporal disaggregation using model: x(t) = + b y(t), x(t) indicator, y(t) unknown target series, low-frequency constraints y.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/temporaldisaggregationI.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Temporal disaggregation using the model: x(t) = a + b y(t), where x(t) is the indicator, y(t) is the unknown target series, with low-frequency constraints on y. — temporaldisaggregationI","text":"","code":"temporaldisaggregationI(   series,   indicator,   conversion = c(\"Sum\", \"Average\", \"Last\", \"First\", \"UserDefined\"),   conversion.obsposition = 1L,   rho = 0,   rho.fixed = FALSE,   rho.truncated = 0 )"},{"path":"https://rjdverse.github.io/rjd3bench/reference/temporaldisaggregationI.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Temporal disaggregation using the model: x(t) = a + b y(t), where x(t) is the indicator, y(t) is the unknown target series, with low-frequency constraints on y. — temporaldisaggregationI","text":"series time series disaggregated. must ts object. indicator High-frequency indicator used temporal disaggregation. must ts object. conversion Conversion mode (Usually \"Sum\" \"Average\") conversion.obsposition Integer. used \"UserDefined\" mode. Position observed indicator aggregated periods (instance 7th month year) rho used Ar1/RwAr1 models. (Initial) value parameter rho.fixed Fixed rho (T/F, F default) rho.truncated Range Rho evaluation ([rho.truncated, 1[)","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/temporaldisaggregationI.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Temporal disaggregation using the model: x(t) = a + b y(t), where x(t) is the indicator, y(t) is the unknown target series, with low-frequency constraints on y. — temporaldisaggregationI","text":"object class \"JD3TempDisaggI\"","code":""},{"path":"https://rjdverse.github.io/rjd3bench/reference/temporaldisaggregationI.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Temporal disaggregation using the model: x(t) = a + b y(t), where x(t) is the indicator, y(t) is the unknown target series, with low-frequency constraints on y. — temporaldisaggregationI","text":"","code":"# Retail data, monthly indicator  Y <- rjd3toolkit::aggregate(rjd3toolkit::Retail$RetailSalesTotal, 1) x <- rjd3toolkit::Retail$FoodAndBeverageStores td <- temporaldisaggregationI(Y, indicator = x) td$estimation$disagg #>           Jan      Feb      Mar      Apr      May      Jun      Jul      Aug #> 1992 126151.4 107410.9 128083.0 138396.0 165377.2 148824.2 179437.6 162492.2 #> 1993 138578.9 103853.3 147321.3 154540.9 174656.3 164929.5 196067.4 162563.4 #> 1994 143711.3 111338.0 174125.7 160660.8 179163.6 185013.2 198812.3 186296.7 #> 1995 157744.7 122590.1 182487.1 171984.8 197568.6 195306.7 203727.9 199054.0 #> 1996 168801.1 150593.4 192395.0 175203.8 215880.4 198191.9 215626.8 222696.2 #> 1997 188775.7 139600.5 211453.1 177757.2 231046.3 195106.7 229075.3 225673.2 #> 1998 195702.9 143675.5 193913.8 203268.2 235965.9 209780.0 246758.5 227308.7 #> 1999 201904.1 161675.4 222343.0 214726.9 250130.7 226500.0 266879.7 232348.2 #> 2000 200329.0 188374.8 243243.7 240487.6 264050.4 259951.0 271167.5 261848.0 #> 2001 218689.3 185385.5 252820.8 229993.8 278607.6 263469.7 266290.1 275438.1 #> 2002 239435.6 194734.5 274322.7 221790.5 291738.3 260931.5 280568.5 283542.4 #> 2003 258443.8 201870.3 259341.4 254237.1 300870.3 262128.4 300489.9 292429.7 #> 2004 277071.5 224932.4 269161.8 273311.7 310803.0 282978.2 320414.4 284596.1 #> 2005 279487.2 227552.6 306711.8 282930.1 319830.6 309543.4 331711.0 314943.2 #> 2006 281369.3 245794.0 311854.9 302747.5 345947.5 329893.0 344140.0 340467.3 #> 2007 308963.2 261435.7 337115.2 302853.0 364124.3 345379.8 346735.5 347791.7 #> 2008 315459.7 280849.6 332383.8 297965.3 374023.1 324658.0 359978.5 353838.4 #> 2009 304064.3 218875.8 275031.9 286571.0 337270.9 295391.4 330278.4 310191.8 #> 2010 295612.1 244320.7 316694.0 297897.3 346458.2 313042.9 348997.5 324778.6 #>           Sep      Oct      Nov      Dec #> 1992 138640.0 162249.5 143931.0 214723.1 #> 1993 151499.7 162525.5 154638.2 231073.7 #> 1994 172389.3 172191.3 173629.2 252689.8 #> 1995 178460.4 171743.8 184036.5 257799.5 #> 1996 173486.7 197135.6 206172.9 250481.2 #> 1997 186432.7 212337.4 208126.7 268618.2 #> 1998 201331.8 225928.6 208958.5 294512.6 #> 1999 225827.4 234265.3 228935.9 343019.5 #> 2000 240853.8 235249.4 250610.0 332590.7 #> 2001 240754.2 251222.2 266005.5 339048.2 #> 2002 231047.3 256872.8 276188.9 323149.0 #> 2003 249837.0 275818.6 274172.2 338515.4 #> 2004 277356.2 290904.0 289442.8 379457.8 #> 2005 298932.0 306274.0 310994.2 407780.8 #> 2006 308481.4 316987.5 333050.8 419402.9 #> 2007 309502.6 321701.1 342018.5 418177.2 #> 2008 295511.5 324602.7 320836.1 372826.3 #> 2009 279697.2 310369.3 301353.7 389375.3 #> 2010 308656.4 331646.0 336461.7 424899.6  # qna data, quarterly indicator data(\"qna_data\") Y <- ts(qna_data$B1G_Y_data[,\"B1G_CE\"], frequency = 1, start = c(2009,1)) x <- ts(qna_data$TURN_Q_data[,\"TURN_INDEX_CE\"], frequency = 4, start = c(2009,1)) td <- temporaldisaggregationI(Y, indicator = x) td$regression$a #> [1] 28.43446 td$regression$b #> [1] 0.0303505"},{"path":"https://rjdverse.github.io/rjd3bench/news/index.html","id":"rjd3bench-3009000","dir":"Changelog","previous_headings":"","what":"rjd3bench 3.0.0.9000","title":"rjd3bench 3.0.0.9000","text":"notable changes project documented file. format based Keep Changelog, project adheres Semantic Versioning.","code":""},{"path":"https://rjdverse.github.io/rjd3bench/news/index.html","id":"unreleased-3-0-0-9000","dir":"Changelog","previous_headings":"","what":"Unreleased","title":"rjd3bench 3.0.0.9000","text":"Add function documentation vignette multivariate Cholette","code":""},{"path":[]},{"path":"https://rjdverse.github.io/rjd3bench/news/index.html","id":"added-3-0-0-9000","dir":"Changelog","previous_headings":"3.0.0 - 2025-05-12","what":"Added","title":"rjd3bench 3.0.0.9000","text":"Add function temporal_disaggregation_raw() TD atypical frequency data Add function denton_raw() benchmarking atypical frequency data Add alternative objective functions (backwards, symmetric logarithmic) GRP method Additional content functions documentation /vignette temporal disaggregation (Chow-Lin) benchmarking (Denton, GRP, Cholette)","code":""},{"path":"https://rjdverse.github.io/rjd3bench/news/index.html","id":"changed-3-0-0-9000","dir":"Changelog","previous_headings":"3.0.0 - 2025-05-12","what":"Changed","title":"rjd3bench 3.0.0.9000","text":"Split TD interpolation. main function temporaldisaggregation() deprecated replaced two functions temporal_disaggregation() temporal_interpolation() arguments temporal_disaggregation(), temporal_interpolation() denton() functions added extend possibilities user. Refactoring vignette","code":""},{"path":"https://rjdverse.github.io/rjd3bench/news/index.html","id":"fixed-3-0-0-9000","dir":"Changelog","previous_headings":"3.0.0 - 2025-05-12","what":"Fixed","title":"rjd3bench 3.0.0.9000","text":"Solve issue residual output tests fail Solve instability issue multivariatecholette()","code":""},{"path":[]},{"path":"https://rjdverse.github.io/rjd3bench/news/index.html","id":"added-3-0-0-9000-1","dir":"Changelog","previous_headings":"2.1.0 - 2024-07-18","what":"Added","title":"rjd3bench 3.0.0.9000","text":"Add output residuals temporaldisaggregation() function","code":""},{"path":[]},{"path":"https://rjdverse.github.io/rjd3bench/news/index.html","id":"changed-3-0-0-9000-1","dir":"Changelog","previous_headings":"2.0.1 - 2024-07-12","what":"Changed","title":"rjd3bench 3.0.0.9000","text":"new jars related version 1.2.1*","code":""},{"path":[]},{"path":"https://rjdverse.github.io/rjd3bench/news/index.html","id":"added-3-0-0-9000-2","dir":"Changelog","previous_headings":"2.0.0 - 2023-12-12","what":"Added","title":"rjd3bench 3.0.0.9000","text":"v2.0.0","code":""},{"path":[]},{"path":"https://rjdverse.github.io/rjd3bench/news/index.html","id":"added-3-0-0-9000-3","dir":"Changelog","previous_headings":"1.0.0 - 2023-07-06","what":"Added","title":"rjd3bench 3.0.0.9000","text":"Initial commit","code":""}]
